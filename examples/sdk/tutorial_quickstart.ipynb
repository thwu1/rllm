{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fb27b941602401d91542211134fc71a",
   "metadata": {},
   "source": [
    "# RLLM SDK Quick Start: Make Any Agent Trainable With Almost No Adaptation\n",
    "\n",
    "This tutorial shows how to make **any existing agent code** trainable with minimal changes.\n",
    "\n",
    "**The key insight:** Just replace your OpenAI client with the SDK client, and everything is automatically tracked for training!\n",
    "\n",
    "*Note: This tutorial focuses on showing you the mechanics. We'll explain how training works at the end.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acae54e37e7d407bbb7b55eff062a284",
   "metadata": {},
   "source": [
    "## Step 1: Start the Proxy\n",
    "\n",
    "Start the proxy for testing. During training, the Trainer manages this automatically. The proxy logs all LLM calls to a SQLite database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a63283cbaf04dbcab1f6479b197f3a8",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from rllm.sdk.proxy.proxy_manager import ProxyManager\n",
    "\n",
    "# Setup\n",
    "DB_PATH = \"/tmp/rllm_demo.db\"\n",
    "MODEL = \"gpt-4o-mini\"\n",
    "\n",
    "openai_api_key = \"sk-xxx\"  # Fill your openai api key\n",
    "\n",
    "# Clean up\n",
    "Path(DB_PATH).unlink(missing_ok=True)\n",
    "\n",
    "# Start proxy\n",
    "proxy_manager = ProxyManager(proxy_port=4000, admin_token=\"my-shared-secret\")\n",
    "config = {\n",
    "    \"model_list\": [\n",
    "        {\n",
    "            \"model_name\": MODEL,\n",
    "            \"litellm_params\": {\n",
    "                \"model\": MODEL,\n",
    "                \"api_key\": openai_api_key,\n",
    "            },\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "proxy_manager.start_proxy_subprocess(config=config, db_path=DB_PATH, project=\"demo\")\n",
    "proxy_url = proxy_manager.get_proxy_url(include_v1=True)\n",
    "\n",
    "print(f\"âœ“ Proxy started at {proxy_url}\")\n",
    "print(f\"âœ“ Database: {DB_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd0d8092fe74a7c96281538738b07e2",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!python rllm/examples/solver_judge/prepare_countdown_data.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72eea5119410473aa328ad9291626812",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from rllm.data.dataset import DatasetRegistry\n",
    "\n",
    "train_dataset = DatasetRegistry.load_dataset(\"countdown\", \"train\")\n",
    "test_dataset = DatasetRegistry.load_dataset(\"countdown\", \"test\")\n",
    "\n",
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8edb47106e1a46a883d545849b8ab81b",
   "metadata": {},
   "source": [
    "**The Countdown Task:**  \n",
    "Given a set of numbers and a target, find an arithmetic expression using those numbers to reach the target. Each number can be used at most once. For example: numbers `[30, 32, 76]` and target `78` â†’ solution could be `76 + 32 - 30 = 78`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10185d26023b46108eb7d9f57d49d2b3",
   "metadata": {},
   "source": [
    "## Step 2: Your Original Agent Code\n",
    "\n",
    "A typical agent using the standard OpenAI client. This agent follows a Solver-Judge workflow: generate multiple solution attempts, then select the best one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8763a12b2bbd4a93a75aff182afb95dc",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from openai import AsyncOpenAI\n",
    "import re\n",
    "\n",
    "judge_prompt = \"\"\"You are an expert verifier. Given a countdown problem and multiple solution attempts, select a correct solution.\n",
    "Problem:\n",
    "{problem}\n",
    "Solutions to evaluate:\n",
    "{solutions}\n",
    "A correct solution must satisfy the following criteria:\n",
    "1. The solution uses only the given numbers.\n",
    "2. Each number is used exactly once.\n",
    "3. Only basic arithmetic operations (+, -, *, /) are used.\n",
    "4. The calculation results in the target number.\n",
    "5. The final answer is clearly marked within <answer>...</answer> tags.\n",
    "Output the index of your selected solution within <answer>...</answer> tags, e.g., <answer>1</answer> for the first solution, <answer>2</answer> for the second solution, etc. If multiple solutions are correct, output the index of the first correct solution.\"\"\"\n",
    "\n",
    "\n",
    "class CountdownAgent:\n",
    "    \"\"\"A simple math solving agent - ORIGINAL VERSION\"\"\"\n",
    "\n",
    "    def __init__(self, api_key: str, model: str = \"gpt-4o-mini\"):\n",
    "        # Standard OpenAI client\n",
    "        self.client = AsyncOpenAI(api_key=api_key)\n",
    "        self.model = model\n",
    "\n",
    "    async def solve(self, problem: str) -> str:\n",
    "        \"\"\"Solve a math problem.\"\"\"\n",
    "        response = await self.client.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=[{\"role\": \"user\", \"content\": f\"{problem}. Output the final answer within <answer>...</answer>\"}],\n",
    "            max_tokens=1000,\n",
    "        )\n",
    "        return self.parse_solver_answer(response.choices[0].message.content)\n",
    "\n",
    "    async def judge(self, problem, solutions: list[str]) -> str:\n",
    "        \"\"\"Judge multiple solutions to a problem.\"\"\"\n",
    "        formatted_solutions = \"\\n\".join([f\"Solution {i + 1}:\\n{sol}\\n\" for i, sol in enumerate(solutions)])\n",
    "        prompt = judge_prompt.format(problem=problem, solutions=formatted_solutions)\n",
    "\n",
    "        response = await self.client.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            max_tokens=1000,\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "\n",
    "    def parse_solver_answer(self, solution):\n",
    "        # Find all <answer> tags and return the last one\n",
    "        answer_matches = re.findall(r\"<answer>(.*?)</answer>\", solution, re.IGNORECASE | re.DOTALL)\n",
    "        if answer_matches:\n",
    "            return \"<answer>\" + answer_matches[-1].strip() + \"</answer>\"\n",
    "        return \"No solution found\"\n",
    "\n",
    "    def parse_selected_solution(self, judgment, solutions):\n",
    "        # Find all <answer> tags and use the last one\n",
    "        answer_matches = re.findall(r\"<answer>(.*?)</answer>\", judgment, re.IGNORECASE | re.DOTALL)\n",
    "        if answer_matches:\n",
    "            answer_text = answer_matches[-1].strip()\n",
    "            try:\n",
    "                solution_index = int(answer_text)\n",
    "                return solutions[solution_index - 1]\n",
    "            except (ValueError, IndexError):\n",
    "                return \"\"\n",
    "        return \"\"\n",
    "\n",
    "    async def run(self, problem: str, n_solutions: int = 2) -> str:\n",
    "        \"\"\"Generate multiple solutions and judge them.\"\"\"\n",
    "        solutions = []\n",
    "        for i in range(n_solutions):\n",
    "            sol = await self.solve(problem)\n",
    "            solutions.append(sol)\n",
    "\n",
    "        judgment = await self.judge(problem, solutions)\n",
    "        selected_solution = self.parse_selected_solution(judgment, solutions)\n",
    "        return selected_solution\n",
    "\n",
    "\n",
    "# Use it\n",
    "agent = CountdownAgent(api_key=openai_api_key, model=MODEL)\n",
    "result = await agent.run(train_dataset[0][\"question\"])\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7623eae2785240b9bd12b16a66d81610",
   "metadata": {},
   "source": [
    "## Step 3: Make It Trainable (2 Simple Changes!)\n",
    "\n",
    "**Change 1:** Import the SDK client instead of OpenAI client  \n",
    "**Change 2:** Point to the proxy URL\n",
    "\n",
    "**What's `session()`?** A lightweight primitive that tracks all LLM calls within its scope and injects metadata into each call. Everything inside `with session()` is automatically grouped and retrievable via `sess._uid`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdc8c89c7104fffa095e18ddfef8986",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from rllm.sdk import get_chat_client_async, session  # Change 1: Import SDK client\n",
    "import re\n",
    "\n",
    "\n",
    "class TrainableAgent:\n",
    "    \"\"\"A simple math solving agent - TRAINABLE VERSION\"\"\"\n",
    "\n",
    "    def __init__(self, api_key: str, model: str = \"gpt-4o-mini\"):\n",
    "        # Replace standard OpenAI client with SDK client\n",
    "        # self.client = AsyncOpenAI(api_key=api_key)\n",
    "        self.client = get_chat_client_async(api_key=api_key, base_url=proxy_url)\n",
    "        self.model = model\n",
    "\n",
    "    async def solve(self, problem: str) -> str:\n",
    "        \"\"\"Solve a math problem.\"\"\"\n",
    "        response = await self.client.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=[{\"role\": \"user\", \"content\": f\"{problem}. Output the final answer within <answer>...</answer>\"}],\n",
    "            max_tokens=1000,\n",
    "        )\n",
    "        return self.parse_solver_answer(response.choices[0].message.content)\n",
    "\n",
    "    async def judge(self, problem, solutions: list[str]) -> str:\n",
    "        \"\"\"Judge multiple solutions to a problem.\"\"\"\n",
    "        formatted_solutions = \"\\n\".join([f\"Solution {i + 1}:\\n{sol}\\n\" for i, sol in enumerate(solutions)])\n",
    "        prompt = judge_prompt.format(problem=problem, solutions=formatted_solutions)\n",
    "\n",
    "        response = await self.client.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            max_tokens=1000,\n",
    "        )\n",
    "        return self.parse_solver_answer(response.choices[0].message.content)\n",
    "\n",
    "    def parse_solver_answer(self, solution):\n",
    "        # Find all <answer> tags and return the last one\n",
    "        answer_matches = re.findall(r\"<answer>(.*?)</answer>\", solution, re.IGNORECASE | re.DOTALL)\n",
    "        if answer_matches:\n",
    "            return \"<answer>\" + answer_matches[-1].strip() + \"</answer>\"\n",
    "        return \"No solution found\"\n",
    "\n",
    "    def parse_selected_solution(self, judgment, solutions):\n",
    "        # Find all <answer> tags and use the last one\n",
    "        answer_matches = re.findall(r\"<answer>(.*?)</answer>\", judgment, re.IGNORECASE | re.DOTALL)\n",
    "        if answer_matches:\n",
    "            answer_text = answer_matches[-1].strip()\n",
    "            try:\n",
    "                solution_index = int(answer_text)\n",
    "                return solutions[solution_index - 1]\n",
    "            except (ValueError, IndexError):\n",
    "                return \"\"\n",
    "        return \"\"\n",
    "\n",
    "    async def run(self, problem: str, n_solutions: int = 2) -> str:\n",
    "        \"\"\"Generate multiple solutions and judge them.\"\"\"\n",
    "        solutions = []\n",
    "        for _ in range(n_solutions):\n",
    "            sol = await self.solve(problem)\n",
    "            solutions.append(sol)\n",
    "\n",
    "        judgment = await self.judge(problem, solutions)\n",
    "        selected_solution = self.parse_selected_solution(judgment, solutions)\n",
    "        return selected_solution\n",
    "\n",
    "\n",
    "# # Use it\n",
    "agent = TrainableAgent(api_key=openai_api_key, model=MODEL)\n",
    "with session() as sess:\n",
    "    result = await agent.run(train_dataset[0][\"question\"])\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b118ea5561624da68c537baed56e602f",
   "metadata": {},
   "source": [
    "### Why This Makes It Trainable: Automatic LLM Call Tracking\n",
    "\n",
    "The `session()` primitive enables training by capturing every LLM interaction. You can access all traces directly via `sess.llm_calls`:\n",
    "\n",
    "Each trace contains:\n",
    "- `input`: Prompt messages sent to the model\n",
    "- `output`: Model's response\n",
    "- `tokens`: Exact token IDs (ensures correctness, bypasses retokenization issues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938c804e27f84196a10c8828c723f798",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Access traces directly from the session\n",
    "traces = sess.llm_calls\n",
    "\n",
    "print(f\"âœ… Retrieved {len(traces)} trace(s)\\n\")\n",
    "\n",
    "# Inspect the first trace\n",
    "trace = traces[0]\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"TRACE DETAILS\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Model: {trace.model}\")\n",
    "print(f\"\\nInput Messages:\")\n",
    "for msg in trace.input[\"messages\"]:\n",
    "    print(f\"  [{msg['role']}]: {msg['content']}\")\n",
    "print(f\"\\nOutput:\")\n",
    "print(f\"  {trace.output['choices'][0]['message']['content']}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nðŸ’¡ This trace contains everything you need for training!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504fb2a444614c0babb325280ed9130a",
   "metadata": {},
   "source": [
    "## Step 4: Add Rewards and Train\n",
    "\n",
    "Define a reward function that scores agent outputs, then pass it to the trainer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bbdb311c014d738909a11f9e486628",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43b363d81ae4b689946ece5c682cd59",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def extract_solution(solution_str):\n",
    "    # Look for answer pattern in the entire string\n",
    "    answer_pattern = r\"<answer>(.*?)</answer>\"\n",
    "    match = re.finditer(answer_pattern, solution_str)\n",
    "    matches = list(match)\n",
    "    if matches:\n",
    "        final_answer = matches[-1].group(1).strip()\n",
    "    else:\n",
    "        final_answer = None\n",
    "    return final_answer\n",
    "\n",
    "\n",
    "def validate_equation(equation_str, available_numbers):\n",
    "    \"\"\"Validate that equation only uses available numbers and each number once.\"\"\"\n",
    "    try:\n",
    "        # Extract all numbers from the equation\n",
    "        numbers_in_eq = [int(n) for n in re.findall(r\"\\d+\", equation_str)]\n",
    "\n",
    "        # Check if all numbers in equation are available\n",
    "        available_numbers = sorted(available_numbers)\n",
    "        numbers_in_eq = sorted(numbers_in_eq)\n",
    "\n",
    "        # Each number should be used exactly once\n",
    "        return numbers_in_eq == available_numbers\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "\n",
    "def evaluate_equation(equation_str):\n",
    "    \"\"\"Safely evaluate the arithmetic equation using eval() with precautions.\"\"\"\n",
    "    try:\n",
    "        # Define a regex pattern that only allows numbers, operators, parentheses, and whitespace\n",
    "        allowed_pattern = r\"^[\\d+\\-*/().\\s]+$\"\n",
    "        if not re.match(allowed_pattern, equation_str):\n",
    "            raise ValueError(\"Invalid characters in equation.\")\n",
    "\n",
    "        # Evaluate the equation with restricted globals and locals\n",
    "        result = eval(equation_str, {\"__builtins__\": None}, {})\n",
    "        return result\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "\n",
    "def reward_fn(solution_str, numbers, target):\n",
    "    \"\"\"The scoring function for countdown task.\n",
    "\n",
    "    Args:\n",
    "        solution_str: the solution text\n",
    "        numbers: list of numbers\n",
    "        target: target number\n",
    "\n",
    "    Returns:\n",
    "        float: 1.0 if correct, 0.0 if incorrectet\n",
    "    \"\"\"\n",
    "    equation = extract_solution(solution_str=solution_str)\n",
    "\n",
    "    if equation is None:\n",
    "        return 0.0\n",
    "\n",
    "    # Validate equation uses correct numbers\n",
    "    if not validate_equation(equation, numbers):\n",
    "        return 0.0\n",
    "\n",
    "    # Evaluate equation\n",
    "    try:\n",
    "        result = evaluate_equation(equation)\n",
    "\n",
    "        if result is None:\n",
    "            return 0.0\n",
    "\n",
    "        if abs(result - target) < 1e-5:  # Account for floating point precision\n",
    "            return 1.0\n",
    "        else:\n",
    "            return 0.0\n",
    "    except Exception:\n",
    "        return 0.0\n",
    "\n",
    "\n",
    "async def rollout_v1(question: str, ground_truth: str, nums: list, target: float, model=\"Qwen/Qwen3-4B-Instruct-2507\", **kwargs) -> float:\n",
    "    # we need to provide an rollout function that return a reward\n",
    "    agent = TrainableAgent(api_key=openai_api_key, model=model)\n",
    "    # agent = TrainableAgent(api_key=openai_api_key, model=\"gpt-4o-mini\")\n",
    "    response = await agent.run(question)\n",
    "    print(response)\n",
    "    reward = reward_fn(response, nums, target)\n",
    "    return reward\n",
    "\n",
    "\n",
    "await rollout_v1(**train_dataset[0], model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a65eabff63a45729fe45fb5ade58bdc",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Training\n",
    "from rllm.trainer import AgentTrainer\n",
    "from hydra import initialize_config_dir, compose\n",
    "import os\n",
    "\n",
    "with initialize_config_dir(config_dir=\"/workspace/rllm/examples/sdk\", version_base=None):\n",
    "    config = compose(config_name=\"tutorial_config\")\n",
    "\n",
    "trainer = AgentTrainer(\n",
    "    agent_run_func=rollout_v1,  # or use rollout_v2 for step-level rewards\n",
    "    config=config,\n",
    "    train_dataset=train_dataset,\n",
    "    val_dataset=test_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3933fab20d04ec698c2621248eb3be0",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd4641cc4064e0191573fe9c69df29b",
   "metadata": {},
   "source": [
    "## Bonus: Using @trajectory Decorator for Step-Level Control\n",
    "\n",
    "The `@trajectory` decorator is **equivalent to `with session()`** - both track LLM calls using contextvar.\n",
    "\n",
    "**Key difference:** Both provide `.steps` access for fine-grained control:\n",
    "- `with session() as sess:` â†’ `sess.steps` \n",
    "- `@trajectory(name=\"...\")` â†’ returns `TrajectoryView` with `.steps`\n",
    "\n",
    "**When to use:**\n",
    "- `with session()`: Simple episode tracking\n",
    "- `@trajectory`: Multi-step agents where you want explicit step-level rewards (e.g., reward solver differently from judge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8309879909854d7188b41380fd92a7c3",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from rllm.sdk import trajectory\n",
    "from rllm.sdk.protocol import TrajectoryView\n",
    "\n",
    "\n",
    "class TrainableAgentV2:\n",
    "    \"\"\"A simple math solving agent - TRAINABLE VERSION V2\"\"\"\n",
    "\n",
    "    def __init__(self, api_key: str, model: str = \"gpt-4o-mini\"):\n",
    "        # Replace standard OpenAI client with SDK client\n",
    "        # self.client = AsyncOpenAI(api_key=api_key)\n",
    "        self.client = get_chat_client_async(api_key=api_key, base_url=proxy_url)\n",
    "        self.model = model\n",
    "\n",
    "    @trajectory(name=\"solver\")\n",
    "    async def solve(self, problem: str) -> str:\n",
    "        \"\"\"Solve a math problem.\"\"\"\n",
    "        response = await self.client.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=[{\"role\": \"user\", \"content\": f\"{problem}. Output the final answer within <answer>...</answer>\"}],\n",
    "            max_tokens=1000,\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "\n",
    "    @trajectory(name=\"judge\")\n",
    "    async def judge(self, problem, solutions: list[str]) -> str:\n",
    "        \"\"\"Judge multiple solutions to a problem.\"\"\"\n",
    "        formatted_solutions = \"\\n\".join([f\"Solution {i + 1}:\\n{sol}\\n\" for i, sol in enumerate(solutions)])\n",
    "        prompt = judge_prompt.format(problem=problem, solutions=formatted_solutions)\n",
    "\n",
    "        response = await self.client.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            max_tokens=1000,\n",
    "        )\n",
    "        return self.parse_solver_answer(response.choices[0].message.content)\n",
    "\n",
    "    def parse_solver_answer(self, solution):\n",
    "        # Find all <answer> tags and return the last one\n",
    "        answer_matches = re.findall(r\"<answer>(.*?)</answer>\", solution, re.IGNORECASE | re.DOTALL)\n",
    "        if answer_matches:\n",
    "            return \"<answer>\" + answer_matches[-1].strip() + \"</answer>\"\n",
    "        return \"No solution found\"\n",
    "\n",
    "    def parse_selected_solution(self, judgment, solutions):\n",
    "        # Find all <answer> tags and use the last one\n",
    "        answer_matches = re.findall(r\"<answer>(.*?)</answer>\", judgment, re.IGNORECASE | re.DOTALL)\n",
    "        if answer_matches:\n",
    "            answer_text = answer_matches[-1].strip()\n",
    "            try:\n",
    "                solution_index = int(answer_text)\n",
    "                return solutions[solution_index - 1]\n",
    "            except (ValueError, IndexError):\n",
    "                return \"\"\n",
    "        return \"\"\n",
    "\n",
    "    async def run(self, problem: str, n_solutions: int = 2, ground_truth: str = None) -> str:\n",
    "        \"\"\"Generate multiple solutions and judge them.\"\"\"\n",
    "        solutions = []\n",
    "        for _ in range(n_solutions):\n",
    "            sol = await self.solve(problem)\n",
    "            solutions.append(sol)\n",
    "\n",
    "        judgment = await self.judge(problem, solutions)\n",
    "        selected_solution = self.parse_selected_solution(judgment.result, solutions)\n",
    "\n",
    "        # assign reward for each step in trajectory\n",
    "        for sol in solutions:\n",
    "            sol.reward = reward_fn(sol.result, ground_truth)\n",
    "            sol.steps[0].reward = sol.reward\n",
    "\n",
    "        judgment.reward = reward_fn(selected_solution, ground_truth)\n",
    "        judgment.steps[0].reward = judgment.reward\n",
    "\n",
    "        return solutions + [judgment]\n",
    "\n",
    "\n",
    "# Use it\n",
    "async def rollout_v2(question: str, ground_truth: str, **kwargs) -> list[TrajectoryView]:\n",
    "    agent = TrainableAgentV2(None, model=\"Qwen/Qwen3-4B-Instruct-2507\")\n",
    "    trajs = await agent.run(question, ground_truth=ground_truth)\n",
    "    return trajs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed186c9a28b402fb0bc4494df01f08d",
   "metadata": {},
   "source": [
    "## How Does Training Work?\n",
    "\n",
    "Here's what happens under the hood:\n",
    "\n",
    "1. **Trace Collection:** The proxy captures all LLM calls (inputs, outputs, tokens, latency)\n",
    "2. **Reward Assignment:** You define what's good (correct answer = 1.0, wrong = 0.0)\n",
    "3. **Training Loop:** The trainer feeds traces + rewards to the model\n",
    "4. **Learning:** The model adjusts weights to maximize rewards\n",
    "5. **Improvement:** Over time, the model learns successful behaviors\n",
    "\n",
    "This is reinforcement learning: try different approaches, get feedback, learn what works."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1e1581032b452c9409d6c6813c49d1",
   "metadata": {},
   "source": [
    "## Design Details (For The Curious)\n",
    "\n",
    "**Why a proxy?**  \n",
    "Transparent LLM call interception without modifying agent code. Works with any OpenAI-compatible API.\n",
    "\n",
    "**How does session tracking work?**  \n",
    "Uses Python's **contextvar** for automatic context propagation. `with session()` or `@trajectory` creates a context that automatically groups all LLM calls inside it. Thread-safe, zero manual tracking.\n",
    "\n",
    "**Session vs Trajectory:**  \n",
    "Both use contextvar under the hood:\n",
    "- `with session()`: Returns session object with `._uid` for retrieval\n",
    "- `@trajectory`: Returns `TrajectoryView` with `.steps` for fine-grained control\n",
    "\n",
    "**Why SQLite storage?**  \n",
    "Offline training with no live service dependencies. Query and analyze traces anytime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379cbbc1e968416e875cc15c1202d7eb",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Cleanup\n",
    "proxy_manager.shutdown_proxy()\n",
    "print(\"âœ“ Proxy shutdown complete\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
