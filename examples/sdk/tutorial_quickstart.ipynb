{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fb27b941602401d91542211134fc71a",
   "metadata": {},
   "source": [
    "# RLLM SDK Quick Start: Make Any Agent Trainable With Almost No Adaptation\n",
    "\n",
    "This tutorial shows how to make **any existing agent code** trainable with minimal changes.\n",
    "\n",
    "**The key insight:** Just replace your OpenAI client with the SDK client, and everything is automatically tracked for training!\n",
    "\n",
    "*Note: This tutorial focuses on showing you the mechanics. We'll explain how training works at the end.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acae54e37e7d407bbb7b55eff062a284",
   "metadata": {},
   "source": [
    "## Step 1: Start the Proxy\n",
    "\n",
    "Start the proxy for testing. During training, the Trainer manages this automatically. The proxy logs all LLM calls to a SQLite database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a63283cbaf04dbcab1f6479b197f3a8",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Proxy started at http://127.0.0.1:4000/v1\n",
      "âœ“ Database: /tmp/rllm_demo.db\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from rllm.sdk.proxy.proxy_manager import ProxyManager\n",
    "\n",
    "# Setup\n",
    "DB_PATH = \"/tmp/rllm_demo.db\"\n",
    "MODEL = \"gpt-4o-mini\"\n",
    "\n",
    "openai_api_key = \"sk-xxx\"  # Fill your openai api key\n",
    "\n",
    "# Clean up\n",
    "Path(DB_PATH).unlink(missing_ok=True)\n",
    "\n",
    "# Start proxy\n",
    "proxy_manager = ProxyManager(proxy_port=4000, admin_token=\"my-shared-secret\")\n",
    "config = {\n",
    "    \"model_list\": [\n",
    "        {\n",
    "            \"model_name\": MODEL,\n",
    "            \"litellm_params\": {\n",
    "                \"model\": MODEL,\n",
    "                \"api_key\": openai_api_key,\n",
    "            },\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "proxy_manager.start_proxy_subprocess(config=config, db_path=DB_PATH, project=\"demo\")\n",
    "proxy_url = proxy_manager.get_proxy_url(include_v1=True)\n",
    "\n",
    "print(f\"âœ“ Proxy started at {proxy_url}\")\n",
    "print(f\"âœ“ Database: {DB_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8dd0d8092fe74a7c96281538738b07e2",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\rREADME.md:   0%|                                      | 0.00/314 [00:00<?, ?B/s]\rREADME.md: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 314/314 [00:00<00:00, 3.51MB/s]\r\n",
      "\rdata/train-00000-of-00001.parquet:   0%|            | 0.00/2.85M [00:00<?, ?B/s]\rdata/train-00000-of-00001.parquet: 100%|â–ˆâ–ˆâ–ˆ| 2.85M/2.85M [00:00<00:00, 4.95MB/s]\rdata/train-00000-of-00001.parquet: 100%|â–ˆâ–ˆâ–ˆ| 2.85M/2.85M [00:00<00:00, 4.94MB/s]\r\n",
      "\rGenerating train split:   0%|                 | 0/490364 [00:00<?, ? examples/s]\rGenerating train split: 100%|â–ˆ| 490364/490364 [00:00<00:00, 4879458.53 examples/\rGenerating train split: 100%|â–ˆ| 490364/490364 [00:00<00:00, 4867126.43 examples/\r\n",
      "\rMap:   0%|                                    | 0/489340 [00:00<?, ? examples/s]\rMap:   0%|                      | 2280/489340 [00:00<00:21, 22645.45 examples/s]\rMap:   1%|â–                     | 4630/489340 [00:00<00:20, 23140.09 examples/s]\rMap:   1%|â–Ž                     | 6988/489340 [00:00<00:20, 23336.43 examples/s]\rMap:   2%|â–                    | 10453/489340 [00:00<00:20, 23215.15 examples/s]\rMap:   3%|â–Œ                    | 12815/489340 [00:00<00:20, 23344.14 examples/s]\rMap:   3%|â–‹                    | 16283/489340 [00:00<00:20, 23248.05 examples/s]\rMap:   4%|â–Š                    | 18635/489340 [00:00<00:20, 23322.95 examples/s]\rMap:   4%|â–‰                    | 20997/489340 [00:00<00:20, 23404.96 examples/s]\rMap:   5%|â–ˆ                    | 23540/489340 [00:01<00:26, 17369.87 examples/s]\rMap:   5%|â–ˆ                    | 25856/489340 [00:01<00:24, 18702.53 examples/s]\rMap:   6%|â–ˆâ–                   | 28160/489340 [00:01<00:23, 19674.65 examples/s]\rMap:   6%|â–ˆâ–Ž                   | 30500/489340 [00:01<00:22, 20642.12 examples/s]\rMap:   7%|â–ˆâ–                   | 32828/489340 [00:01<00:21, 21355.20 examples/s]\rMap:   7%|â–ˆâ–Œ                   | 35072/489340 [00:01<00:20, 21654.23 examples/s]\rMap:   8%|â–ˆâ–Œ                   | 37388/489340 [00:01<00:20, 22080.78 examples/s]\rMap:   8%|â–ˆâ–‹                   | 39721/489340 [00:01<00:20, 22437.94 examples/s]\rMap:   9%|â–ˆâ–Š                   | 43178/489340 [00:01<00:19, 22630.43 examples/s]\rMap:   9%|â–ˆâ–‰                   | 45517/489340 [00:02<00:19, 22830.27 examples/s]\rMap:  10%|â–ˆâ–ˆ                   | 47846/489340 [00:02<00:19, 22954.28 examples/s]\rMap:  10%|â–ˆâ–ˆâ–                  | 51316/489340 [00:02<00:19, 22893.67 examples/s]\rMap:  11%|â–ˆâ–ˆâ–Ž                  | 53620/489340 [00:02<00:19, 22930.22 examples/s]\rMap:  11%|â–ˆâ–ˆâ–                  | 55947/489340 [00:02<00:18, 23018.72 examples/s]\rMap:  12%|â–ˆâ–ˆâ–Œ                  | 59373/489340 [00:02<00:18, 22951.97 examples/s]\rMap:  13%|â–ˆâ–ˆâ–‹                  | 61698/489340 [00:02<00:18, 23027.53 examples/s]\rMap:  13%|â–ˆâ–ˆâ–Š                  | 65173/489340 [00:02<00:18, 22961.80 examples/s]\rMap:  14%|â–ˆâ–ˆâ–‰                  | 67482/489340 [00:03<00:18, 22989.77 examples/s]\rMap:  14%|â–ˆâ–ˆâ–‰                  | 69799/489340 [00:03<00:18, 23034.15 examples/s]\rMap:  15%|â–ˆâ–ˆâ–ˆâ–                 | 73179/489340 [00:03<00:18, 22847.86 examples/s]\rMap:  15%|â–ˆâ–ˆâ–ˆâ–                 | 75479/489340 [00:03<00:18, 22884.34 examples/s]\rMap:  16%|â–ˆâ–ˆâ–ˆâ–                 | 78933/489340 [00:03<00:17, 22929.84 examples/s]\rMap:  17%|â–ˆâ–ˆâ–ˆâ–Œ                 | 82319/489340 [00:03<00:17, 22807.42 examples/s]\rMap:  17%|â–ˆâ–ˆâ–ˆâ–‹                 | 84630/489340 [00:03<00:17, 22879.65 examples/s]\rMap:  18%|â–ˆâ–ˆâ–ˆâ–‹                 | 86941/489340 [00:03<00:17, 22935.89 examples/s]\rMap:  18%|â–ˆâ–ˆâ–ˆâ–‰                 | 90340/489340 [00:04<00:17, 22834.82 examples/s]\rMap:  19%|â–ˆâ–ˆâ–ˆâ–‰                 | 92661/489340 [00:04<00:17, 22927.27 examples/s]\rMap:  19%|â–ˆâ–ˆâ–ˆâ–ˆ                 | 94984/489340 [00:04<00:17, 23006.29 examples/s]\rMap:  20%|â–ˆâ–ˆâ–ˆâ–ˆâ–                | 98383/489340 [00:04<00:17, 22877.97 examples/s]\rMap:  21%|â–ˆâ–ˆâ–ˆâ–ˆ                | 100696/489340 [00:04<00:16, 22940.66 examples/s]\rMap:  21%|â–ˆâ–ˆâ–ˆâ–ˆâ–               | 103000/489340 [00:04<00:16, 22872.89 examples/s]\rMap:  22%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž               | 105299/489340 [00:04<00:16, 22902.54 examples/s]\rMap:  22%|â–ˆâ–ˆâ–ˆâ–ˆâ–               | 107625/489340 [00:04<00:16, 23001.66 examples/s]\rMap:  22%|â–ˆâ–ˆâ–ˆâ–ˆâ–               | 109956/489340 [00:04<00:16, 23088.94 examples/s]\rMap:  23%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹               | 113361/489340 [00:05<00:16, 22939.15 examples/s]\rMap:  24%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹               | 115676/489340 [00:05<00:16, 22992.43 examples/s]\rMap:  24%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š               | 119068/489340 [00:05<00:16, 22850.76 examples/s]\rMap:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰               | 121392/489340 [00:05<00:16, 22948.49 examples/s]\rMap:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ               | 123702/489340 [00:05<00:15, 22987.39 examples/s]\rMap:  26%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–              | 127159/489340 [00:05<00:15, 22848.87 examples/s]\rMap:  26%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž              | 129471/489340 [00:05<00:15, 22914.65 examples/s]\rMap:  27%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–              | 131775/489340 [00:05<00:15, 22945.15 examples/s]\rMap:  28%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ              | 135162/489340 [00:05<00:15, 22794.76 examples/s]\rMap:  28%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ              | 137462/489340 [00:06<00:15, 22845.80 examples/s]\rMap:  29%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹              | 139774/489340 [00:06<00:15, 22919.11 examples/s]\rMap:  29%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š              | 143159/489340 [00:06<00:15, 22763.91 examples/s]\rMap:  30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰              | 145469/489340 [00:06<00:15, 22849.40 examples/s]\rMap:  30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ              | 147777/489340 [00:06<00:14, 22908.93 examples/s]\rMap:  31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–             | 151183/489340 [00:06<00:14, 22831.09 examples/s]\rMap:  31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž             | 153516/489340 [00:06<00:14, 22956.29 examples/s]\rMap:  32%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž             | 155844/489340 [00:06<00:14, 23040.54 examples/s]\rMap:  32%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–             | 158155/489340 [00:06<00:14, 22876.46 examples/s]\rMap:  33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ             | 160487/489340 [00:07<00:14, 22999.49 examples/s]\rMap:  33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹             | 162821/489340 [00:07<00:14, 23094.52 examples/s]\rMap:  34%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š             | 166229/489340 [00:07<00:14, 22950.49 examples/s]\rMap:  34%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰             | 168560/489340 [00:07<00:13, 23042.34 examples/s]\rMap:  35%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰             | 170878/489340 [00:07<00:13, 23076.14 examples/s]\rMap:  36%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–            | 174339/489340 [00:07<00:13, 22988.81 examples/s]\rMap:  36%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–            | 176651/489340 [00:07<00:13, 23021.29 examples/s]\rMap:  37%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž            | 178976/489340 [00:07<00:13, 23081.52 examples/s]\rMap:  37%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–            | 182397/489340 [00:08<00:13, 22978.52 examples/s]\rMap:  38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ            | 184734/489340 [00:08<00:13, 23078.51 examples/s]\rMap:  38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹            | 188164/489340 [00:08<00:13, 22984.08 examples/s]\rMap:  39%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š            | 190491/489340 [00:08<00:12, 23052.95 examples/s]\rMap:  39%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰            | 192818/489340 [00:08<00:12, 23107.84 examples/s]\rMap:  40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ            | 196263/489340 [00:08<00:12, 23052.92 examples/s]\rMap:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ            | 198610/489340 [00:08<00:12, 23156.37 examples/s]\rMap:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–           | 200954/489340 [00:08<00:12, 23229.81 examples/s]\rMap:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž           | 204386/489340 [00:09<00:12, 23097.93 examples/s]\rMap:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–           | 206715/489340 [00:09<00:12, 23147.20 examples/s]\rMap:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ           | 210166/489340 [00:09<00:12, 23032.34 examples/s]\rMap:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹           | 212498/489340 [00:09<00:11, 23102.72 examples/s]\rMap:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š           | 214844/489340 [00:09<00:11, 23196.48 examples/s]\rMap:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰           | 218328/489340 [00:09<00:11, 23083.61 examples/s]\rMap:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ           | 220671/489340 [00:09<00:11, 23170.16 examples/s]\rMap:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ           | 223000/489340 [00:09<00:11, 23053.86 examples/s]\rMap:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–          | 225335/489340 [00:09<00:11, 23131.75 examples/s]\rMap:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž          | 227678/489340 [00:10<00:11, 23214.62 examples/s]\rMap:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–          | 231171/489340 [00:10<00:11, 23135.47 examples/s]\rMap:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ          | 233499/489340 [00:10<00:11, 23169.41 examples/s]\rMap:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹          | 235822/489340 [00:10<00:10, 23183.33 examples/s]\rMap:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š          | 239251/489340 [00:10<00:10, 23061.50 examples/s]\rMap:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š          | 241584/489340 [00:10<00:10, 23128.80 examples/s]\rMap:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰          | 243917/489340 [00:10<00:10, 23182.12 examples/s]\rMap:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ          | 247372/489340 [00:10<00:10, 23124.00 examples/s]\rMap:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–         | 249694/489340 [00:10<00:10, 23146.48 examples/s]\rMap:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž         | 253176/489340 [00:11<00:10, 23100.02 examples/s]\rMap:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–         | 255497/489340 [00:11<00:10, 23125.07 examples/s]\rMap:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ         | 257824/489340 [00:11<00:09, 23161.87 examples/s]\rMap:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹         | 261237/489340 [00:11<00:09, 23010.77 examples/s]\rMap:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š         | 263557/489340 [00:11<00:09, 23057.09 examples/s]\rMap:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š         | 265881/489340 [00:11<00:09, 23104.41 examples/s]\rMap:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ         | 269340/489340 [00:11<00:09, 23024.62 examples/s]\rMap:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ         | 271682/489340 [00:11<00:09, 23122.10 examples/s]\rMap:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 274000/489340 [00:12<00:09, 22971.65 examples/s]\rMap:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž        | 276339/489340 [00:12<00:09, 23084.76 examples/s]\rMap:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 278660/489340 [00:12<00:09, 23117.25 examples/s]\rMap:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 280997/489340 [00:12<00:08, 23188.49 examples/s]\rMap:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ        | 284427/489340 [00:12<00:08, 23062.75 examples/s]\rMap:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹        | 286746/489340 [00:12<00:08, 23094.41 examples/s]\rMap:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š        | 290188/489340 [00:12<00:08, 23035.94 examples/s]\rMap:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰        | 292527/489340 [00:12<00:08, 23123.61 examples/s]\rMap:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ        | 294869/489340 [00:12<00:08, 23201.39 examples/s]\rMap:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–       | 298340/489340 [00:13<00:08, 23082.43 examples/s]\rMap:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž       | 300677/489340 [00:13<00:08, 23154.64 examples/s]\rMap:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–       | 303000/489340 [00:13<00:08, 23027.84 examples/s]\rMap:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–       | 305536/489340 [00:13<00:10, 17427.78 examples/s]\rMap:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ       | 307872/489340 [00:13<00:09, 18761.44 examples/s]\rMap:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹       | 310170/489340 [00:13<00:09, 19722.30 examples/s]\rMap:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š       | 312522/489340 [00:13<00:08, 20697.08 examples/s]\rMap:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š       | 314869/489340 [00:13<00:08, 21440.53 examples/s]\rMap:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰       | 317160/489340 [00:14<00:07, 21793.95 examples/s]\rMap:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ       | 319516/489340 [00:14<00:07, 22293.52 examples/s]\rMap:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–      | 321869/489340 [00:14<00:07, 22649.49 examples/s]\rMap:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–      | 324179/489340 [00:14<00:07, 22675.82 examples/s]\rMap:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž      | 326521/489340 [00:14<00:07, 22890.60 examples/s]\rMap:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–      | 328862/489340 [00:14<00:06, 23041.29 examples/s]\rMap:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ      | 332353/489340 [00:14<00:06, 23053.50 examples/s]\rMap:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹      | 334697/489340 [00:14<00:06, 23154.46 examples/s]\rMap:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š      | 338178/489340 [00:14<00:06, 23127.65 examples/s]\rMap:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰      | 340517/489340 [00:15<00:06, 23193.06 examples/s]\rMap:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ      | 342876/489340 [00:15<00:06, 23298.96 examples/s]\rMap:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–     | 346349/489340 [00:15<00:06, 23217.38 examples/s]\rMap:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 348694/489340 [00:15<00:06, 23273.04 examples/s]\rMap:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–     | 352178/489340 [00:15<00:05, 23184.83 examples/s]\rMap:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–     | 354515/489340 [00:15<00:05, 23229.82 examples/s]\rMap:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 356854/489340 [00:15<00:05, 23270.54 examples/s]\rMap:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 360349/489340 [00:15<00:05, 23168.11 examples/s]\rMap:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 362705/489340 [00:15<00:05, 23265.81 examples/s]\rMap:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 366172/489340 [00:16<00:05, 23179.54 examples/s]\rMap:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 368512/489340 [00:16<00:05, 23233.46 examples/s]\rMap:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 372000/489340 [00:16<00:05, 23110.01 examples/s]\rMap:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 374345/489340 [00:16<00:04, 23191.22 examples/s]\rMap:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 376689/489340 [00:16<00:04, 23254.16 examples/s]\rMap:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 380169/489340 [00:16<00:04, 23144.27 examples/s]\rMap:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 382512/489340 [00:16<00:04, 23214.59 examples/s]\rMap:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 384859/489340 [00:16<00:04, 23281.19 examples/s]\rMap:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 388345/489340 [00:17<00:04, 23177.01 examples/s]\rMap:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 390684/489340 [00:17<00:04, 23228.62 examples/s]\rMap:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 394175/489340 [00:17<00:04, 23138.30 examples/s]\rMap:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 396511/489340 [00:17<00:04, 23192.91 examples/s]\rMap:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 398848/489340 [00:17<00:03, 23235.04 examples/s]\rMap:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 401178/489340 [00:17<00:03, 23147.17 examples/s]\rMap:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 403527/489340 [00:17<00:03, 23240.95 examples/s]\rMap:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 405870/489340 [00:17<00:03, 23291.37 examples/s]\rMap:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 409350/489340 [00:17<00:03, 23204.00 examples/s]\rMap:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 411689/489340 [00:18<00:03, 23250.82 examples/s]\rMap:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 415177/489340 [00:18<00:03, 23186.87 examples/s]\rMap:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 417518/489340 [00:18<00:03, 23242.22 examples/s]\rMap:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 419862/489340 [00:18<00:02, 23292.32 examples/s]\rMap:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 423340/489340 [00:18<00:02, 23159.78 examples/s]\rMap:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 425666/489340 [00:18<00:02, 23184.09 examples/s]\rMap:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 428000/489340 [00:18<00:02, 23079.42 examples/s]\rMap:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 430340/489340 [00:18<00:02, 23165.08 examples/s]\rMap:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 433832/489340 [00:19<00:02, 23204.80 examples/s]\rMap:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 437273/489340 [00:19<00:02, 23111.24 examples/s]\rMap:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 439604/489340 [00:19<00:02, 23157.51 examples/s]\rMap:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 441947/489340 [00:19<00:02, 23226.41 examples/s]\rMap:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 445386/489340 [00:19<00:01, 23114.26 examples/s]\rMap:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 447721/489340 [00:19<00:01, 23173.66 examples/s]\rMap:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 451167/489340 [00:19<00:01, 23076.71 examples/s]\rMap:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 453505/489340 [00:19<00:01, 23152.02 examples/s]\rMap:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 455843/489340 [00:19<00:01, 23211.10 examples/s]\rMap:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 458170/489340 [00:20<00:01, 23087.22 examples/s]\rMap:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 460506/489340 [00:20<00:01, 23162.83 examples/s]\rMap:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 462841/489340 [00:20<00:01, 23215.93 examples/s]\rMap:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 465170/489340 [00:20<00:01, 23082.14 examples/s]\rMap:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 467505/489340 [00:20<00:00, 23157.59 examples/s]\rMap:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 469842/489340 [00:20<00:00, 23217.76 examples/s]\rMap:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 472167/489340 [00:20<00:00, 23055.39 examples/s]\rMap:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 474499/489340 [00:20<00:00, 23130.19 examples/s]\rMap:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 476840/489340 [00:20<00:00, 23210.13 examples/s]\rMap:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 479169/489340 [00:20<00:00, 23080.06 examples/s]\rMap:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 481512/489340 [00:21<00:00, 23181.90 examples/s]\rMap:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 483841/489340 [00:21<00:00, 23212.31 examples/s]\rMap:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 486174/489340 [00:21<00:00, 23080.12 examples/s]\rMap: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 488495/489340 [00:21<00:00, 23117.51 examples/s]\rMap: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 489340/489340 [00:21<00:00, 22828.04 examples/s]\r\n",
      "\rMap:   0%|                                      | 0/1024 [00:00<?, ? examples/s]\rMap: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1024/1024 [00:00<00:00, 21976.67 examples/s]\r\n",
      "Train dataset size: 489340\r\n",
      "Test dataset size: 1024\r\n",
      "Stage 2 train dataset size: 50000\r\n",
      "Stage 3 train dataset size: 50000\r\n",
      "Train dataset path: /workspace/rllm/rllm/data/datasets/countdown/train.parquet\r\n",
      "Test dataset path: /workspace/rllm/rllm/data/datasets/countdown/test.parquet\r\n",
      "Stage 2 train dataset path: /workspace/rllm/rllm/data/datasets/countdown/stage2_train.parquet\r\n",
      "Stage 3 train dataset path: /workspace/rllm/rllm/data/datasets/countdown/stage3_train.parquet\r\n",
      "\r\n",
      "Sample train example:\r\n",
      "{'target': 78, 'nums': array([30, 32, 76]), 'question': 'Using the numbers 30, 32, 76, find a way to reach the target number 78. You can use basic arithmetic operations (+, -, *, /) and each number can only be used once. Show your step-by-step calculation and output the final answer within <answer>...</answer>, for example <answer> (1 + 2) / 3 </answer>.', 'ground_truth': '78', 'data_source': 'countdown'}\r\n",
      "\r\n",
      "Sample stage 2 train example:\r\n",
      "{'target': 84, 'nums': array([83, 98, 98]), 'question': 'Using the numbers 83, 98, 98, find a way to reach the target number 84. You can use basic arithmetic operations (+, -, *, /) and each number can only be used once. Show your step-by-step calculation and output the final answer within <answer>...</answer>, for example <answer> (1 + 2) / 3 </answer>.', 'ground_truth': '84', 'data_source': 'countdown'}\r\n",
      "\r\n",
      "Sample stage 3 train example:\r\n",
      "{'target': 32, 'nums': array([64,  1, 92,  3]), 'question': 'Using the numbers 64, 1, 92, 3, find a way to reach the target number 32. You can use basic arithmetic operations (+, -, *, /) and each number can only be used once. Show your step-by-step calculation and output the final answer within <answer>...</answer>, for example <answer> (1 + 2) / 3 </answer>.', 'ground_truth': '32', 'data_source': 'countdown'}\r\n"
     ]
    }
   ],
   "source": [
    "!python rllm/examples/solver_judge/prepare_countdown_data.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72eea5119410473aa328ad9291626812",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{'target': 78,\n 'nums': [30, 32, 76],\n 'question': 'Using the numbers 30, 32, 76, find a way to reach the target number 78. You can use basic arithmetic operations (+, -, *, /) and each number can only be used once. Show your step-by-step calculation and output the final answer within <answer>...</answer>, for example <answer> (1 + 2) / 3 </answer>.',\n 'ground_truth': '78',\n 'data_source': 'countdown'}"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rllm.data.dataset import DatasetRegistry\n",
    "\n",
    "train_dataset = DatasetRegistry.load_dataset(\"countdown\", \"train\")\n",
    "test_dataset = DatasetRegistry.load_dataset(\"countdown\", \"test\")\n",
    "\n",
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8edb47106e1a46a883d545849b8ab81b",
   "metadata": {},
   "source": [
    "**The Countdown Task:**  \n",
    "Given a set of numbers and a target, find an arithmetic expression using those numbers to reach the target. Each number can be used at most once. For example: numbers `[30, 32, 76]` and target `78` â†’ solution could be `76 + 32 - 30 = 78`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10185d26023b46108eb7d9f57d49d2b3",
   "metadata": {},
   "source": [
    "## Step 2: Your Original Agent Code\n",
    "\n",
    "A typical agent using the standard OpenAI client. This agent follows a Solver-Judge workflow: generate multiple solution attempts, then select the best one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8763a12b2bbd4a93a75aff182afb95dc",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<answer>(76 + 32) - 30</answer>\n"
     ]
    }
   ],
   "source": [
    "from openai import AsyncOpenAI\n",
    "import re\n",
    "\n",
    "judge_prompt = \"\"\"You are an expert verifier. Given a countdown problem and multiple solution attempts, select a correct solution.\n",
    "Problem:\n",
    "{problem}\n",
    "Solutions to evaluate:\n",
    "{solutions}\n",
    "A correct solution must satisfy the following criteria:\n",
    "1. The solution uses only the given numbers.\n",
    "2. Each number is used exactly once.\n",
    "3. Only basic arithmetic operations (+, -, *, /) are used.\n",
    "4. The calculation results in the target number.\n",
    "5. The final answer is clearly marked within <answer>...</answer> tags.\n",
    "Output the index of your selected solution within <answer>...</answer> tags, e.g., <answer>1</answer> for the first solution, <answer>2</answer> for the second solution, etc. If multiple solutions are correct, output the index of the first correct solution.\"\"\"\n",
    "\n",
    "\n",
    "class CountdownAgent:\n",
    "    \"\"\"A simple math solving agent - ORIGINAL VERSION\"\"\"\n",
    "\n",
    "    def __init__(self, api_key: str, model: str = \"gpt-4o-mini\"):\n",
    "        # Standard OpenAI client\n",
    "        self.client = AsyncOpenAI(api_key=api_key)\n",
    "        self.model = model\n",
    "\n",
    "    async def solve(self, problem: str) -> str:\n",
    "        \"\"\"Solve a math problem.\"\"\"\n",
    "        response = await self.client.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=[{\"role\": \"user\", \"content\": f\"{problem}. Output the final answer within <answer>...</answer>\"}],\n",
    "            max_tokens=1000,\n",
    "        )\n",
    "        return self.parse_solver_answer(response.choices[0].message.content)\n",
    "\n",
    "    async def judge(self, problem, solutions: list[str]) -> str:\n",
    "        \"\"\"Judge multiple solutions to a problem.\"\"\"\n",
    "        formatted_solutions = \"\\n\".join([f\"Solution {i + 1}:\\n{sol}\\n\" for i, sol in enumerate(solutions)])\n",
    "        prompt = judge_prompt.format(problem=problem, solutions=formatted_solutions)\n",
    "\n",
    "        response = await self.client.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            max_tokens=1000,\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "\n",
    "    def parse_solver_answer(self, solution):\n",
    "        # Find all <answer> tags and return the last one\n",
    "        answer_matches = re.findall(r\"<answer>(.*?)</answer>\", solution, re.IGNORECASE | re.DOTALL)\n",
    "        if answer_matches:\n",
    "            return \"<answer>\" + answer_matches[-1].strip() + \"</answer>\"\n",
    "        return \"No solution found\"\n",
    "\n",
    "    def parse_selected_solution(self, judgment, solutions):\n",
    "        # Find all <answer> tags and use the last one\n",
    "        answer_matches = re.findall(r\"<answer>(.*?)</answer>\", judgment, re.IGNORECASE | re.DOTALL)\n",
    "        if answer_matches:\n",
    "            answer_text = answer_matches[-1].strip()\n",
    "            try:\n",
    "                solution_index = int(answer_text)\n",
    "                return solutions[solution_index - 1]\n",
    "            except (ValueError, IndexError):\n",
    "                return \"\"\n",
    "        return \"\"\n",
    "\n",
    "    async def run(self, problem: str, n_solutions: int = 2) -> str:\n",
    "        \"\"\"Generate multiple solutions and judge them.\"\"\"\n",
    "        solutions = []\n",
    "        for i in range(n_solutions):\n",
    "            sol = await self.solve(problem)\n",
    "            solutions.append(sol)\n",
    "\n",
    "        judgment = await self.judge(problem, solutions)\n",
    "        selected_solution = self.parse_selected_solution(judgment, solutions)\n",
    "        return selected_solution\n",
    "\n",
    "\n",
    "# Use it\n",
    "agent = CountdownAgent(api_key=openai_api_key, model=MODEL)\n",
    "result = await agent.run(train_dataset[0][\"question\"])\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7623eae2785240b9bd12b16a66d81610",
   "metadata": {},
   "source": [
    "## Step 3: Make It Trainable (2 Simple Changes!)\n",
    "\n",
    "**Change 1:** Import the SDK client instead of OpenAI client  \n",
    "**Change 2:** Point to the proxy URL\n",
    "\n",
    "**What's `session()`?** A lightweight primitive that tracks all LLM calls within its scope and injects metadata into each call. Everything inside `with session()` is automatically grouped and retrievable via `sess._uid`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7cdc8c89c7104fffa095e18ddfef8986",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<answer>(76 - 30) + 32</answer>\n"
     ]
    }
   ],
   "source": [
    "from rllm.sdk import get_chat_client_async, session  # Change 1: Import SDK client\n",
    "import re\n",
    "\n",
    "\n",
    "class TrainableAgent:\n",
    "    \"\"\"A simple math solving agent - TRAINABLE VERSION\"\"\"\n",
    "\n",
    "    def __init__(self, api_key: str, model: str = \"gpt-4o-mini\"):\n",
    "        # Replace standard OpenAI client with SDK client\n",
    "        # self.client = AsyncOpenAI(api_key=api_key)\n",
    "        self.client = get_chat_client_async(api_key=api_key, base_url=proxy_url)\n",
    "        self.model = model\n",
    "\n",
    "    async def solve(self, problem: str) -> str:\n",
    "        \"\"\"Solve a math problem.\"\"\"\n",
    "        response = await self.client.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=[{\"role\": \"user\", \"content\": f\"{problem}. Output the final answer within <answer>...</answer>\"}],\n",
    "            max_tokens=1000,\n",
    "        )\n",
    "        return self.parse_solver_answer(response.choices[0].message.content)\n",
    "\n",
    "    async def judge(self, problem, solutions: list[str]) -> str:\n",
    "        \"\"\"Judge multiple solutions to a problem.\"\"\"\n",
    "        formatted_solutions = \"\\n\".join([f\"Solution {i + 1}:\\n{sol}\\n\" for i, sol in enumerate(solutions)])\n",
    "        prompt = judge_prompt.format(problem=problem, solutions=formatted_solutions)\n",
    "\n",
    "        response = await self.client.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            max_tokens=1000,\n",
    "        )\n",
    "        return self.parse_solver_answer(response.choices[0].message.content)\n",
    "\n",
    "    def parse_solver_answer(self, solution):\n",
    "        # Find all <answer> tags and return the last one\n",
    "        answer_matches = re.findall(r\"<answer>(.*?)</answer>\", solution, re.IGNORECASE | re.DOTALL)\n",
    "        if answer_matches:\n",
    "            return \"<answer>\" + answer_matches[-1].strip() + \"</answer>\"\n",
    "        return \"No solution found\"\n",
    "\n",
    "    def parse_selected_solution(self, judgment, solutions):\n",
    "        # Find all <answer> tags and use the last one\n",
    "        answer_matches = re.findall(r\"<answer>(.*?)</answer>\", judgment, re.IGNORECASE | re.DOTALL)\n",
    "        if answer_matches:\n",
    "            answer_text = answer_matches[-1].strip()\n",
    "            try:\n",
    "                solution_index = int(answer_text)\n",
    "                return solutions[solution_index - 1]\n",
    "            except (ValueError, IndexError):\n",
    "                return \"\"\n",
    "        return \"\"\n",
    "\n",
    "    async def run(self, problem: str, n_solutions: int = 2) -> str:\n",
    "        \"\"\"Generate multiple solutions and judge them.\"\"\"\n",
    "        solutions = []\n",
    "        for _ in range(n_solutions):\n",
    "            sol = await self.solve(problem)\n",
    "            solutions.append(sol)\n",
    "\n",
    "        judgment = await self.judge(problem, solutions)\n",
    "        selected_solution = self.parse_selected_solution(judgment, solutions)\n",
    "        return selected_solution\n",
    "\n",
    "\n",
    "# # Use it\n",
    "agent = TrainableAgent(api_key=openai_api_key, model=MODEL)\n",
    "with session() as sess:\n",
    "    result = await agent.run(train_dataset[0][\"question\"])\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b118ea5561624da68c537baed56e602f",
   "metadata": {},
   "source": [
    "### Why This Makes It Trainable: Automatic LLM Call Tracking\n",
    "\n",
    "The `session()` primitive enables training by capturing every LLM interaction. You can access all traces directly via `sess.llm_calls`:\n",
    "\n",
    "Each trace contains:\n",
    "- `input`: Prompt messages sent to the model\n",
    "- `output`: Model's response\n",
    "- `tokens`: Exact token IDs (ensures correctness, bypasses retokenization issues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "938c804e27f84196a10c8828c723f798",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Retrieved 3 trace(s)\n",
      "\n",
      "======================================================================\n",
      "TRACE DETAILS\n",
      "======================================================================\n",
      "Model: gpt-4o-mini\n",
      "\n",
      "Input Messages:\n",
      "  [user]: Using the numbers 30, 32, 76, find a way to reach the target number 78. You can use basic arithmetic operations (+, -, *, /) and each number can only be used once. Show your step-by-step calculation and output the final answer within <answer>...</answer>, for example <answer> (1 + 2) / 3 </answer>.. Output the final answer within <answer>...</answer>\n",
      "\n",
      "Output:\n",
      "  To reach the target number 78 using the numbers 30, 32, and 76 with basic arithmetic operations, we can follow these steps:\n",
      "\n",
      "1. **First, letâ€™s add 30 to 76**:\n",
      "   \\[\n",
      "   30 + 76 = 106\n",
      "   \\]\n",
      "\n",
      "2. **Now, since we want to reach 78, we can subtract 32 from the result obtained in step 1**:\n",
      "   \\[\n",
      "   106 - 32 = 74\n",
      "   \\]\n",
      "\n",
      "3. **Next, we need two more to reach 78, which we can achieve by adding 4**:\n",
      "   Since we are looking for a series of operations, we realize that directly with these numbers, we can try instead:\n",
      "\n",
      "   Another way could be:\n",
      "   - **Subtract 30 from 76**:\n",
      "   \\[\n",
      "   76 - 30 = 46\n",
      "   \\]\n",
      "   - **Then, we add 32 to this**:\n",
      "   \\[\n",
      "   46 + 32 = 78\n",
      "   \\]\n",
      "\n",
      "Thus, combining these steps gives us the calculation needed to obtain 78 from 30, 32, and 76. \n",
      "\n",
      "The final answer is:\n",
      "<answer>(76 - 30) + 32</answer>\n",
      "======================================================================\n",
      "\n",
      "ðŸ’¡ This trace contains everything you need for training!\n"
     ]
    }
   ],
   "source": [
    "# Access traces directly from the session\n",
    "traces = sess.llm_calls\n",
    "\n",
    "print(f\"âœ… Retrieved {len(traces)} trace(s)\\n\")\n",
    "\n",
    "# Inspect the first trace\n",
    "trace = traces[0]\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"TRACE DETAILS\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Model: {trace.model}\")\n",
    "print(f\"\\nInput Messages:\")\n",
    "for msg in trace.input[\"messages\"]:\n",
    "    print(f\"  [{msg['role']}]: {msg['content']}\")\n",
    "print(f\"\\nOutput:\")\n",
    "print(f\"  {trace.output['choices'][0]['message']['content']}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nðŸ’¡ This trace contains everything you need for training!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504fb2a444614c0babb325280ed9130a",
   "metadata": {},
   "source": [
    "## Step 4: Add Rewards and Train\n",
    "\n",
    "Define a reward function that scores agent outputs, then pass it to the trainer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59bbdb311c014d738909a11f9e486628",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{'target': 78,\n 'nums': [30, 32, 76],\n 'question': 'Using the numbers 30, 32, 76, find a way to reach the target number 78. You can use basic arithmetic operations (+, -, *, /) and each number can only be used once. Show your step-by-step calculation and output the final answer within <answer>...</answer>, for example <answer> (1 + 2) / 3 </answer>.',\n 'ground_truth': '78',\n 'data_source': 'countdown'}"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b43b363d81ae4b689946ece5c682cd59",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<answer>(76 + 32) - 30</answer>\n"
     ]
    },
    {
     "data": {
      "text/plain": "1.0"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_solution(solution_str):\n",
    "    # Look for answer pattern in the entire string\n",
    "    answer_pattern = r\"<answer>(.*?)</answer>\"\n",
    "    match = re.finditer(answer_pattern, solution_str)\n",
    "    matches = list(match)\n",
    "    if matches:\n",
    "        final_answer = matches[-1].group(1).strip()\n",
    "    else:\n",
    "        final_answer = None\n",
    "    return final_answer\n",
    "\n",
    "\n",
    "def validate_equation(equation_str, available_numbers):\n",
    "    \"\"\"Validate that equation only uses available numbers and each number once.\"\"\"\n",
    "    try:\n",
    "        # Extract all numbers from the equation\n",
    "        numbers_in_eq = [int(n) for n in re.findall(r\"\\d+\", equation_str)]\n",
    "\n",
    "        # Check if all numbers in equation are available\n",
    "        available_numbers = sorted(available_numbers)\n",
    "        numbers_in_eq = sorted(numbers_in_eq)\n",
    "\n",
    "        # Each number should be used exactly once\n",
    "        return numbers_in_eq == available_numbers\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "\n",
    "def evaluate_equation(equation_str):\n",
    "    \"\"\"Safely evaluate the arithmetic equation using eval() with precautions.\"\"\"\n",
    "    try:\n",
    "        # Define a regex pattern that only allows numbers, operators, parentheses, and whitespace\n",
    "        allowed_pattern = r\"^[\\d+\\-*/().\\s]+$\"\n",
    "        if not re.match(allowed_pattern, equation_str):\n",
    "            raise ValueError(\"Invalid characters in equation.\")\n",
    "\n",
    "        # Evaluate the equation with restricted globals and locals\n",
    "        result = eval(equation_str, {\"__builtins__\": None}, {})\n",
    "        return result\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "\n",
    "def reward_fn(solution_str, numbers, target):\n",
    "    \"\"\"The scoring function for countdown task.\n",
    "\n",
    "    Args:\n",
    "        solution_str: the solution text\n",
    "        numbers: list of numbers\n",
    "        target: target number\n",
    "\n",
    "    Returns:\n",
    "        float: 1.0 if correct, 0.0 if incorrectet\n",
    "    \"\"\"\n",
    "    equation = extract_solution(solution_str=solution_str)\n",
    "\n",
    "    if equation is None:\n",
    "        return 0.0\n",
    "\n",
    "    # Validate equation uses correct numbers\n",
    "    if not validate_equation(equation, numbers):\n",
    "        return 0.0\n",
    "\n",
    "    # Evaluate equation\n",
    "    try:\n",
    "        result = evaluate_equation(equation)\n",
    "\n",
    "        if result is None:\n",
    "            return 0.0\n",
    "\n",
    "        if abs(result - target) < 1e-5:  # Account for floating point precision\n",
    "            return 1.0\n",
    "        else:\n",
    "            return 0.0\n",
    "    except Exception:\n",
    "        return 0.0\n",
    "\n",
    "\n",
    "async def rollout_v1(question: str, ground_truth: str, nums: list, target: float, model=\"Qwen/Qwen3-4B-Instruct-2507\", **kwargs) -> float:\n",
    "    # we need to provide an rollout function that return a reward\n",
    "    agent = TrainableAgent(api_key=openai_api_key, model=model)\n",
    "    # agent = TrainableAgent(api_key=openai_api_key, model=\"gpt-4o-mini\")\n",
    "    response = await agent.run(question)\n",
    "    print(response)\n",
    "    reward = reward_fn(response, nums, target)\n",
    "    return reward\n",
    "\n",
    "\n",
    "await rollout_v1(**train_dataset[0], model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a65eabff63a45729fe45fb5ade58bdc",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Training\n",
    "from rllm.trainer import AgentTrainer\n",
    "from hydra import initialize_config_dir, compose\n",
    "import os\n",
    "\n",
    "with initialize_config_dir(config_dir=\"/workspace/rllm/examples/sdk\", version_base=None):\n",
    "    config = compose(config_name=\"tutorial_config\")\n",
    "\n",
    "trainer = AgentTrainer(\n",
    "    agent_run_func=rollout_v1,  # or use rollout_v2 for step-level rewards\n",
    "    config=config,\n",
    "    train_dataset=train_dataset,\n",
    "    val_dataset=test_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3933fab20d04ec698c2621248eb3be0",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-19 03:52:30,870\tINFO worker.py:1908 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n",
      "2025-11-19 03:52:31,698\tINFO packaging.py:588 -- Creating a file package for local module '/workspace'.\n",
      "2025-11-19 03:52:32,809\tINFO packaging.py:380 -- Pushing file package 'gcs://_ray_pkg_d80ef6786f7cd5fa.zip' (50.50MiB) to Ray cluster...\n",
      "2025-11-19 03:52:32,998\tINFO packaging.py:393 -- Successfully pushed file package 'gcs://_ray_pkg_d80ef6786f7cd5fa.zip'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m TaskRunner hostname: modal, PID: 4769\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m {'actor_rollout_ref': {'actor': {'_target_': 'verl.workers.config.FSDPActorConfig',\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                  'checkpoint': {'_target_': 'verl.trainer.config.CheckpointConfig',\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                 'async_save': False,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                 'load_contents': ['model',\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                                   'optimizer',\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                                   'extra'],\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                 'save_contents': ['model',\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                                   'optimizer',\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                                   'extra']},\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                  'clip_ratio': 0.2,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                  'clip_ratio_c': 3.0,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                  'clip_ratio_high': 0.28,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                  'clip_ratio_low': 0.2,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                  'entropy_checkpointing': False,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                  'entropy_coeff': 0.0,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                  'entropy_from_logits_with_chunking': False,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                  'freeze_vision_tower': False,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                  'fsdp_config': {'_target_': 'verl.workers.config.FSDPEngineConfig',\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                  'entropy_checkpointing': False,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                  'entropy_from_logits_with_chunking': False,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                  'forward_only': False,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                  'forward_prefetch': False,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                  'fsdp_size': -1,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                  'model_dtype': 'fp32',\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                  'offload_policy': False,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                  'optimizer_offload': True,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                  'param_offload': True,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                  'reshard_after_forward': True,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                  'strategy': 'fsdp',\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                  'ulysses_sequence_parallel_size': 1,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                  'use_orig_params': False,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                  'use_torch_compile': True,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                  'wrap_policy': {'min_num_params': 0}},\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                  'grad_clip': 1.0,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                  'kl_loss_coef': 0.001,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                  'kl_loss_type': 'low_var_kl',\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                  'loss_agg_mode': 'seq-mean-token-mean',\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                  'optim': {'_target_': 'verl.workers.config.FSDPOptimizerConfig',\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                            'betas': [0.9, 0.999],\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                            'clip_grad': 1.0,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                            'lr': 1e-06,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                            'lr_scheduler_type': 'constant',\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                            'lr_warmup_steps': -1,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                            'lr_warmup_steps_ratio': 0.0,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                            'min_lr_ratio': 0.0,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                            'num_cycles': 0.5,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                            'total_training_steps': -1,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                            'warmup_style': None,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                            'weight_decay': 0.01},\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                  'policy_loss': {'_target_': 'verl.workers.config.PolicyLossConfig',\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                  'clip_cov_lb': 1.0,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                  'clip_cov_ratio': 0.0002,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                  'clip_cov_ub': 5.0,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                  'kl_cov_ratio': 0.0002,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                  'loss_mode': 'vanilla',\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                  'ppo_kl_coef': 0.1},\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                  'ppo_epochs': 1,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                  'ppo_max_token_len_per_gpu': 32768,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                  'ppo_micro_batch_size': None,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                  'ppo_micro_batch_size_per_gpu': None,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                  'ppo_mini_batch_size': 2,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                  'profiler': {'_target_': 'verl.utils.profiler.ProfilerConfig',\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                               'all_ranks': False,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                               'enable': False,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                               'ranks': [],\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                               'save_path': 'outputs/profile',\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                               'tool': None,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                               'tool_config': {'npu': {'_target_': 'verl.utils.profiler.config.NPUToolConfig',\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                                       'analysis': True,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                                       'contents': [],\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                                       'discrete': False,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                                       'level': 'level1'},\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                               'nsys': {'_target_': 'verl.utils.profiler.config.NsightToolConfig',\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                                        'discrete': False},\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                               'torch': {'_target_': 'verl.utils.profiler.config.TorchProfilerToolConfig',\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                                         'step_end': None,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                                         'step_start': 0},\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                               'torch_memory': {'_target_': 'verl.utils.profiler.config.TorchMemoryToolConfig',\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                                                'stack_depth': 32,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                                                'trace_alloc_max_entries': 100000}}},\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                  'shuffle': False,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                  'strategy': 'fsdp',\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                  'ulysses_sequence_parallel_size': 1,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                  'use_dynamic_bsz': True,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                  'use_fused_kernels': False,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                  'use_kl_loss': False,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                  'use_remove_padding': True,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                  'use_torch_compile': True},\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                        'hybrid_engine': True,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                        'model': {'_target_': 'verl.workers.config.HFModelConfig',\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                  'custom_chat_template': None,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                  'enable_activation_offload': False,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                  'enable_gradient_checkpointing': True,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                  'exclude_modules': None,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                  'external_lib': None,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                  'fused_kernel_options': {'impl_backend': 'torch'},\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                  'hf_config_path': None,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                  'lora_alpha': 16,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                  'lora_rank': 0,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                  'override_config': {},\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                  'path': 'Qwen/Qwen3-4B-Instruct-2507',\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                  'target_modules': 'all-linear',\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                  'tokenizer_path': None,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                  'trust_remote_code': False,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                  'use_fused_kernels': False,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                  'use_liger': False,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                  'use_remove_padding': True,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                  'use_shm': False},\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                        'nccl_timeout': 600,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                        'ref': {'entropy_checkpointing': False,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                'entropy_from_logits_with_chunking': False,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                'fsdp_config': {'_target_': 'verl.workers.config.FSDPEngineConfig',\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                'entropy_checkpointing': False,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                'entropy_from_logits_with_chunking': False,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                'forward_only': False,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                'forward_prefetch': False,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                'fsdp_size': -1,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                'model_dtype': 'fp32',\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                'offload_policy': False,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                'optimizer_offload': False,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                'param_offload': True,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                'reshard_after_forward': True,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                'strategy': 'fsdp',\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                'ulysses_sequence_parallel_size': 1,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                'use_orig_params': False,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                'use_torch_compile': True,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                'wrap_policy': {'min_num_params': 0}},\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                'log_prob_max_token_len_per_gpu': 32768,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                'log_prob_micro_batch_size': None,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                'log_prob_micro_batch_size_per_gpu': None,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                'log_prob_use_dynamic_bsz': True,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                'model': None,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                'profiler': {'_target_': 'verl.utils.profiler.ProfilerConfig',\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                             'all_ranks': False,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                             'enable': False,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                             'ranks': [],\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                             'save_path': 'outputs/profile',\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                             'tool': None,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                             'tool_config': {'npu': {'_target_': 'verl.utils.profiler.config.NPUToolConfig',\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                                     'analysis': True,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                                     'contents': [],\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                                     'discrete': False,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                                     'level': 'level1'},\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                             'nsys': {'_target_': 'verl.utils.profiler.config.NsightToolConfig',\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                                      'discrete': False},\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                             'torch': {'_target_': 'verl.utils.profiler.config.TorchProfilerToolConfig',\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                                       'step_end': None,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                                       'step_start': 0},\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                             'torch_memory': {'_target_': 'verl.utils.profiler.config.TorchMemoryToolConfig',\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                                              'stack_depth': 32,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                                              'trace_alloc_max_entries': 100000}}},\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                'strategy': 'fsdp',\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                'ulysses_sequence_parallel_size': 1,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                'use_torch_compile': True},\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                        'rollout': {'_target_': 'verl.workers.config.RolloutConfig',\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                    'agent': {'_target_': 'verl.workers.config.AgentLoopConfig',\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                              'agent_loop_config_path': None,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                              'custom_async_server': {'_target_': 'verl.workers.config.CustomAsyncServerConfig',\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                                      'name': None,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                                      'path': None},\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                              'default_agent_loop': 'single_turn_agent',\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                              'num_workers': 0},\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                    'calculate_log_probs': False,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                    'cudagraph_capture_sizes': None,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                    'data_parallel_size': 1,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                    'disable_log_stats': True,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                    'do_sample': True,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                    'dtype': 'bfloat16',\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                    'enable_chunked_prefill': True,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                    'enable_prefix_caching': True,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                    'enforce_eager': False,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                    'engine_kwargs': {'sglang': {}, 'vllm': {}},\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                    'expert_parallel_size': 1,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                    'free_cache_engine': True,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                    'gpu_memory_utilization': 0.7,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                    'ignore_eos': False,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                    'layered_summon': False,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                    'load_format': 'dummy',\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                    'log_prob_max_token_len_per_gpu': 32768,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                    'log_prob_micro_batch_size': None,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                    'log_prob_micro_batch_size_per_gpu': None,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                    'log_prob_use_dynamic_bsz': True,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                    'max_model_len': None,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                    'max_num_batched_tokens': 8192,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                    'max_num_seqs': 1024,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                    'mode': 'async',\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                    'multi_stage_wake_up': False,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                    'multi_turn': {'_target_': 'verl.workers.config.MultiTurnConfig',\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                   'enable': False,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                   'format': 'hermes',\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                   'interaction_config_path': None,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                   'max_assistant_turns': None,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                   'max_parallel_calls': 1,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                   'max_tool_response_length': 256,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                   'max_user_turns': None,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                   'num_repeat_rollouts': None,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                   'tokenization_sanity_check_mode': 'strict',\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                   'tool_config_path': None,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                   'tool_response_truncate_side': 'middle',\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                   'use_inference_chat_template': False},\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                    'n': 4,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                    'name': 'vllm',\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                    'over_sample_rate': 0,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                    'pipeline_model_parallel_size': 1,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                    'profiler': {'_target_': 'verl.utils.profiler.ProfilerConfig',\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                 'all_ranks': False,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                 'enable': False,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                 'ranks': [],\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                 'save_path': 'outputs/profile',\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                 'tool': None,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                 'tool_config': {'npu': {'_target_': 'verl.utils.profiler.config.NPUToolConfig',\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                                         'analysis': True,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                                         'contents': [],\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                                         'discrete': False,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                                         'level': 'level1'},\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                                 'nsys': {'_target_': 'verl.utils.profiler.config.NsightToolConfig',\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                                          'discrete': False},\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                                 'torch': {'_target_': 'verl.utils.profiler.config.TorchProfilerToolConfig',\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                                           'step_end': None,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                                           'step_start': 0},\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                                 'torch_memory': {'_target_': 'verl.utils.profiler.config.TorchMemoryToolConfig',\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                                                  'stack_depth': 32,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                                                  'trace_alloc_max_entries': 100000}}},\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                    'prompt_length': 2048,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                    'response_length': 1024,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                    'skip_dump_dir': '/tmp/rollout_dump',\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                    'skip_rollout': False,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                    'skip_tokenizer_init': True,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                    'temperature': 1.0,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                    'tensor_model_parallel_size': 1,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                    'top_k': -1,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                    'top_p': 1.0,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                    'trace': {'_target_': 'verl.workers.config.TraceConfig',\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                              'backend': None,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                              'token2text': False},\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                    'update_weights_bucket_megabytes': 512,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                    'val_kwargs': {'_target_': 'verl.workers.config.SamplingConfig',\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                   'do_sample': True,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                   'n': 1,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                   'temperature': 1.0,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                   'top_k': -1,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                   'top_p': 1.0}}},\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m  'algorithm': {'_target_': 'verl.trainer.config.AlgoConfig',\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                'adv_estimator': 'grpo',\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                'gamma': 1.0,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                'kl_ctrl': {'_target_': 'verl.trainer.config.KLControlConfig',\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                            'horizon': 10000,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                            'kl_coef': 0.001,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                            'target_kl': 0.1,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                            'type': 'fixed'},\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                'kl_penalty': 'kl',\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                'lam': 1.0,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                'norm_adv_by_std_in_grpo': True,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                'pf_ppo': {'reweight_method': 'pow', 'weight_pow': 2.0},\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                'rollout_is': False,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                'rollout_is_level': 'token',\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                'rollout_is_mode': 'truncate',\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                'rollout_is_threshold': None,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                'rollout_is_threshold_lower': None,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                'rollout_is_veto_threshold': 0.0001,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                'use_kl_in_reward': False,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                'use_pf_ppo': False},\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m  'critic': {'_target_': 'verl.workers.config.FSDPCriticConfig',\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m             'checkpoint': {'_target_': 'verl.trainer.config.CheckpointConfig',\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                            'async_save': False,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                            'load_contents': ['model', 'optimizer', 'extra'],\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                            'save_contents': ['model', 'optimizer', 'extra']},\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m             'cliprange_value': 0.5,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m             'enable': None,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m             'forward_max_token_len_per_gpu': 32768,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m             'forward_micro_batch_size': None,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m             'forward_micro_batch_size_per_gpu': None,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m             'grad_clip': 1.0,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m             'loss_agg_mode': 'seq-mean-token-mean',\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m             'model': {'_target_': 'verl.workers.config.FSDPCriticModelCfg',\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                       'enable_activation_offload': False,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                       'enable_gradient_checkpointing': True,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                       'external_lib': None,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                       'fsdp_config': {'_target_': 'verl.workers.config.FSDPEngineConfig',\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                       'entropy_checkpointing': False,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                       'entropy_from_logits_with_chunking': False,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                       'forward_only': False,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                       'forward_prefetch': False,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                       'fsdp_size': -1,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                       'model_dtype': 'fp32',\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                       'offload_policy': False,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                       'optimizer_offload': False,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                       'param_offload': False,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                       'reshard_after_forward': True,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                       'strategy': 'fsdp',\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                       'ulysses_sequence_parallel_size': 1,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                       'use_orig_params': False,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                       'use_torch_compile': True,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                       'wrap_policy': {'min_num_params': 0}},\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                       'lora_alpha': 16,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                       'lora_rank': 0,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                       'override_config': {},\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                       'path': '~/models/deepseek-llm-7b-chat',\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                       'target_modules': 'all-linear',\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                       'tokenizer_path': 'Qwen/Qwen3-4B-Instruct-2507',\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                       'trust_remote_code': False,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                       'use_remove_padding': False,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                       'use_shm': False},\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m             'optim': {'_target_': 'verl.workers.config.FSDPOptimizerConfig',\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                       'betas': [0.9, 0.999],\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                       'clip_grad': 1.0,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                       'lr': 1e-05,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                       'lr_scheduler_type': 'constant',\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                       'lr_warmup_steps': -1,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                       'lr_warmup_steps_ratio': 0.0,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                       'min_lr_ratio': 0.0,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                       'num_cycles': 0.5,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                       'total_training_steps': -1,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                       'warmup_style': None,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                       'weight_decay': 0.01},\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m             'ppo_epochs': 1,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m             'ppo_max_token_len_per_gpu': 32768,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m             'ppo_micro_batch_size': None,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m             'ppo_micro_batch_size_per_gpu': None,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m             'ppo_mini_batch_size': 2,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m             'profiler': {'_target_': 'verl.utils.profiler.ProfilerConfig',\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                          'all_ranks': False,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                          'enable': False,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                          'ranks': [],\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                          'save_path': 'outputs/profile',\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                          'tool': None,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                          'tool_config': {'npu': {'_target_': 'verl.utils.profiler.config.NPUToolConfig',\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                  'analysis': True,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                  'contents': [],\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                  'discrete': False,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                  'level': 'level1'},\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                          'nsys': {'_target_': 'verl.utils.profiler.config.NsightToolConfig',\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                   'discrete': False},\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                          'torch': {'_target_': 'verl.utils.profiler.config.TorchProfilerToolConfig',\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                    'step_end': None,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                    'step_start': 0},\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                          'torch_memory': {'_target_': 'verl.utils.profiler.config.TorchMemoryToolConfig',\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                           'stack_depth': 32,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                           'trace_alloc_max_entries': 100000}}},\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m             'rollout_n': 4,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m             'shuffle': False,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m             'strategy': 'fsdp',\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m             'ulysses_sequence_parallel_size': 1,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m             'use_dynamic_bsz': True},\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m  'custom_reward_function': {'name': 'compute_score', 'path': None},\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m  'data': {'apply_chat_template_kwargs': {},\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m           'custom_cls': {'name': None, 'path': None},\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m           'datagen': {'name': None, 'path': None},\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m           'dataloader_num_workers': 8,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m           'filter_overlong_prompts': False,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m           'filter_overlong_prompts_workers': 1,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m           'gen_batch_size': 4,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m           'image_key': 'images',\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m           'max_prompt_length': 2048,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m           'max_response_length': 1024,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m           'prompt_key': 'prompt',\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m           'return_full_prompt': False,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m           'return_multi_modal_inputs': True,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m           'return_raw_chat': False,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m           'return_raw_input_ids': False,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m           'reward_fn_key': 'data_source',\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m           'sampler': {'class_name': None, 'class_path': None},\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m           'seed': None,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m           'shuffle': True,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m           'tokenizer': None,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m           'train_batch_size': 4,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m           'train_files': '/workspace/rllm/rllm/data/datasets/countdown/train_verl.parquet',\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m           'train_max_samples': -1,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m           'truncation': 'error',\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m           'trust_remote_code': False,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m           'use_shm': False,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m           'val_batch_size': None,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m           'val_files': '/workspace/rllm/rllm/data/datasets/countdown/test_verl.parquet',\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m           'val_max_samples': -1,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m           'validation_shuffle': False,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m           'video_key': 'videos'},\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m  'fireworks': {'concurrency': 32,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                'deployment_id': None,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                'model_id_prefix': 'test-model'},\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m  'global_profiler': {'_target_': 'verl.utils.profiler.ProfilerConfig',\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                      'global_tool_config': {'nsys': {'_target_': 'verl.utils.profiler.config.NsightToolConfig',\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                      'controller_nsight_options': {'cuda-graph-trace': 'graph',\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                                                    'cuda-memory-usage': 'true',\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                                                    'trace': 'cuda,nvtx,cublas,ucx'},\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                      'discrete': False,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                      'worker_nsight_options': {'capture-range': 'cudaProfilerApi',\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                                                'capture-range-end': None,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                                                'cuda-graph-trace': 'graph',\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                                                'cuda-memory-usage': 'true',\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                                                'kill': 'none',\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                                                'trace': 'cuda,nvtx,cublas,ucx'}},\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                             'torch_memory': {'context': 'all',\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                              'kw_args': {},\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                              'stack_depth': 32,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                              'stacks': 'all',\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                              'trace_alloc_max_entries': 100000}},\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                      'profile_continuous_steps': False,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                      'save_path': 'outputs/profile',\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                      'steps': None,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                      'tool': None},\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m  'ray_kwargs': {'ray_init': {'num_cpus': None}, 'timeline_json_file': None},\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m  'reward_model': {'enable': False,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                   'enable_resource_pool': False,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                   'forward_max_token_len_per_gpu': 32768,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                   'launch_reward_fn_async': False,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                   'max_length': None,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                   'micro_batch_size': None,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                   'micro_batch_size_per_gpu': None,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                   'model': {'external_lib': None,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                             'fsdp_config': {'_target_': 'verl.workers.config.FSDPEngineConfig',\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                             'forward_prefetch': False,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                             'fsdp_size': -1,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                             'param_offload': False,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                             'reshard_after_forward': True,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                             'wrap_policy': {'min_num_params': 0}},\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                             'input_tokenizer': 'Qwen/Qwen3-4B-Instruct-2507',\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                             'path': '~/models/FsfairX-LLaMA3-RM-v0.1',\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                             'trust_remote_code': False,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                             'use_fused_kernels': False,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                             'use_remove_padding': False,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                             'use_shm': False},\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                   'n_gpus_per_node': 0,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                   'nnodes': 0,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                   'profiler': {'_target_': 'verl.utils.profiler.ProfilerConfig',\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                'all_ranks': False,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                'enable': False,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                'ranks': [],\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                'save_path': 'outputs/profile',\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                'tool': None,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                'tool_config': {'npu': {'_target_': 'verl.utils.profiler.config.NPUToolConfig',\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                        'analysis': True,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                        'contents': [],\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                        'discrete': False,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                        'level': 'level1'},\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                'nsys': {'_target_': 'verl.utils.profiler.config.NsightToolConfig',\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                         'discrete': False},\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                'torch': {'_target_': 'verl.utils.profiler.config.TorchProfilerToolConfig',\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                          'step_end': None,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                          'step_start': 0},\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                'torch_memory': {'_target_': 'verl.utils.profiler.config.TorchMemoryToolConfig',\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                                 'stack_depth': 32,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                                                 'trace_alloc_max_entries': 100000}}},\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                   'reward_manager': 'naive',\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                   'sandbox_fusion': {'max_concurrent': 64,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                      'memory_limit_mb': 1024,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                      'url': None},\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                   'strategy': 'fsdp',\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                   'ulysses_sequence_parallel_size': 1,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                   'use_dynamic_bsz': True},\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m  'rllm': {'accumulate_reasoning': False,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m           'agent': {'agent_args': {},\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                     'engine_args': {},\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                     'max_steps': 20,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                     'name': 'math_agent',\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                     'overlong_filter': False,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                     'trajectory_timeout': None},\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m           'compact_filtering': {'enable': False,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                 'mask_env_done': False,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                 'mask_error': True,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                 'mask_max_prompt_length_exceeded': True,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                 'mask_max_response_length_exceeded': True,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                 'mask_max_turns_exceeded': False,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                 'mask_timeout': True,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                 'mask_unknown': False},\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m           'disable_thinking': False,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m           'env': {'env_args': {}, 'name': 'custom'},\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m           'filter_token_mismatch': True,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m           'mask_truncated_samples': False,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m           'rejection_sample': {'enable': False, 'multiplier': 1.0},\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m           'sdk': {'processing': {'groupby_key': None, 'traj_name_key': None},\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                   'proxy': {'admin_token': 'my-shared-secret',\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                             'host': '127.0.0.1',\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                             'mode': 'external',\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                             'port': 4000},\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                   'store': {'path': '/tmp/rllm_demo.db'}},\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m           'stepwise_advantage': {'enable': True,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                  'mode': 'per_step',\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                  'normalize_by_steps': False},\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m           'workflow': {'n_parallel_tasks': 16,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                        'name': 'single_turn_workflow',\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                        'retry_limit': 3,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                        'use_workflow': False,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                        'workflow_args': {'agent_args': {},\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                          'agent_cls': None,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                          'env_args': {},\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                          'env_cls': None,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                          'gamma': 0.0,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                          'reward_bonus_coeff': 0.0,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m                                          'timeout': 1000000.0}}},\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m  'trainer': {'balance_batch': True,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m              'critic_warmup': 0,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m              'default_hdfs_dir': None,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m              'default_local_dir': 'checkpoints/solver-judge-workflow/sdk-solver-judge',\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m              'del_local_ckpt_after_load': False,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m              'device': 'cuda',\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m              'episode_log_dir': 'logs/solver-judge-workflow/sdk-solver-judge',\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m              'esi_redundant_time': 0,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m              'experiment_name': 'sdk-solver-judge',\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m              'log_episodes': False,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m              'log_val_generations': 0,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m              'logger': ['console'],\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m              'max_actor_ckpt_to_keep': None,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m              'max_critic_ckpt_to_keep': None,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m              'n_gpus_per_node': 1,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m              'nnodes': 1,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m              'project_name': 'solver-judge-workflow',\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m              'ray_wait_register_center_timeout': 300,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m              'resume_from_path': None,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m              'resume_mode': 'auto',\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m              'rollout_data_dir': None,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m              'save_freq': 200,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m              'test_freq': 10,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m              'total_epochs': 1,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m              'total_training_steps': None,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m              'use_legacy_worker_impl': 'auto',\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m              'val_before_train': False,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m              'val_only': False,\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m              'validation_data_dir': None}}\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m IMPORTANT: Using AgentSdkTrainer\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m Using dataset class: RLHFDataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m /workspace/rllm/verl/verl/trainer/ppo/ray_trainer.py:326: UserWarning: Disabled critic as algorithm.adv_estimator != gae. If it is not intended, please set critic.enable=True\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m   self.use_critic = need_critic(self.config)\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m \rGenerating train split: 0 examples [00:00, ? examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m dataset len: 489340\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m Using dataset class: RLHFDataset\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m dataset len: 1024\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m Size of train dataloader: 122335, Size of val dataloader: 1\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m Total training steps: 122335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m \rGenerating train split: 489340 examples [00:00, 1195483.49 examples/s]\rGenerating train split: 489340 examples [00:00, 1193037.41 examples/s]\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m \rGenerating train split: 0 examples [00:00, ? examples/s]\rGenerating train split: 1024 examples [00:00, 260632.76 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m WARNING 11-19 03:52:53 [api_server.py:1177] LoRA dynamic loading & unloading is enabled in the API server. This should ONLY be used for local development!\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m [VLLM_SERVER_PATCH] Patched vLLMReplica.__init__ to use InstrumentedvLLMHttpServer\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m colocated worker base class <class 'verl.single_controller.base.worker.Worker'>\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m bind role actor_rollout method chat_completion to class <class 'verl.single_controller.ray.base.create_colocated_worker_cls.<locals>.WorkerDict'>\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m bind role actor_rollout method generate to class <class 'verl.single_controller.ray.base.create_colocated_worker_cls.<locals>.WorkerDict'>\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m bind role actor_rollout method get_zeromq_address to class <class 'verl.single_controller.ray.base.create_colocated_worker_cls.<locals>.WorkerDict'>\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m bind role actor_rollout method sleep to class <class 'verl.single_controller.ray.base.create_colocated_worker_cls.<locals>.WorkerDict'>\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m bind role actor_rollout method wake_up to class <class 'verl.single_controller.ray.base.create_colocated_worker_cls.<locals>.WorkerDict'>\n",
      "\u001b[36m(WorkerDict pid=5618)\u001b[0m Model config after override: Qwen3Config {\n",
      "\u001b[36m(WorkerDict pid=5618)\u001b[0m   \"architectures\": [\n",
      "\u001b[36m(WorkerDict pid=5618)\u001b[0m     \"Qwen3ForCausalLM\"\n",
      "\u001b[36m(WorkerDict pid=5618)\u001b[0m   ],\n",
      "\u001b[36m(WorkerDict pid=5618)\u001b[0m   \"attention_bias\": false,\n",
      "\u001b[36m(WorkerDict pid=5618)\u001b[0m   \"attention_dropout\": 0.0,\n",
      "\u001b[36m(WorkerDict pid=5618)\u001b[0m   \"eos_token_id\": 151645,\n",
      "\u001b[36m(WorkerDict pid=5618)\u001b[0m   \"head_dim\": 128,\n",
      "\u001b[36m(WorkerDict pid=5618)\u001b[0m   \"hidden_act\": \"silu\",\n",
      "\u001b[36m(WorkerDict pid=5618)\u001b[0m   \"hidden_size\": 2560,\n",
      "\u001b[36m(WorkerDict pid=5618)\u001b[0m   \"initializer_range\": 0.02,\n",
      "\u001b[36m(WorkerDict pid=5618)\u001b[0m   \"intermediate_size\": 9728,\n",
      "\u001b[36m(WorkerDict pid=5618)\u001b[0m   \"layer_types\": [\n",
      "\u001b[36m(WorkerDict pid=5618)\u001b[0m     \"full_attention\",\n",
      "\u001b[36m(WorkerDict pid=5618)\u001b[0m     \"full_attention\",\n",
      "\u001b[36m(WorkerDict pid=5618)\u001b[0m     \"full_attention\",\n",
      "\u001b[36m(WorkerDict pid=5618)\u001b[0m     \"full_attention\",\n",
      "\u001b[36m(WorkerDict pid=5618)\u001b[0m     \"full_attention\",\n",
      "\u001b[36m(WorkerDict pid=5618)\u001b[0m     \"full_attention\",\n",
      "\u001b[36m(WorkerDict pid=5618)\u001b[0m     \"full_attention\",\n",
      "\u001b[36m(WorkerDict pid=5618)\u001b[0m     \"full_attention\",\n",
      "\u001b[36m(WorkerDict pid=5618)\u001b[0m     \"full_attention\",\n",
      "\u001b[36m(WorkerDict pid=5618)\u001b[0m     \"full_attention\",\n",
      "\u001b[36m(WorkerDict pid=5618)\u001b[0m     \"full_attention\",\n",
      "\u001b[36m(WorkerDict pid=5618)\u001b[0m     \"full_attention\",\n",
      "\u001b[36m(WorkerDict pid=5618)\u001b[0m     \"full_attention\",\n",
      "\u001b[36m(WorkerDict pid=5618)\u001b[0m     \"full_attention\",\n",
      "\u001b[36m(WorkerDict pid=5618)\u001b[0m     \"full_attention\",\n",
      "\u001b[36m(WorkerDict pid=5618)\u001b[0m     \"full_attention\",\n",
      "\u001b[36m(WorkerDict pid=5618)\u001b[0m     \"full_attention\",\n",
      "\u001b[36m(WorkerDict pid=5618)\u001b[0m     \"full_attention\",\n",
      "\u001b[36m(WorkerDict pid=5618)\u001b[0m     \"full_attention\",\n",
      "\u001b[36m(WorkerDict pid=5618)\u001b[0m     \"full_attention\",\n",
      "\u001b[36m(WorkerDict pid=5618)\u001b[0m     \"full_attention\",\n",
      "\u001b[36m(WorkerDict pid=5618)\u001b[0m     \"full_attention\",\n",
      "\u001b[36m(WorkerDict pid=5618)\u001b[0m     \"full_attention\",\n",
      "\u001b[36m(WorkerDict pid=5618)\u001b[0m     \"full_attention\",\n",
      "\u001b[36m(WorkerDict pid=5618)\u001b[0m     \"full_attention\",\n",
      "\u001b[36m(WorkerDict pid=5618)\u001b[0m     \"full_attention\",\n",
      "\u001b[36m(WorkerDict pid=5618)\u001b[0m     \"full_attention\",\n",
      "\u001b[36m(WorkerDict pid=5618)\u001b[0m     \"full_attention\",\n",
      "\u001b[36m(WorkerDict pid=5618)\u001b[0m     \"full_attention\",\n",
      "\u001b[36m(WorkerDict pid=5618)\u001b[0m     \"full_attention\",\n",
      "\u001b[36m(WorkerDict pid=5618)\u001b[0m     \"full_attention\",\n",
      "\u001b[36m(WorkerDict pid=5618)\u001b[0m     \"full_attention\",\n",
      "\u001b[36m(WorkerDict pid=5618)\u001b[0m     \"full_attention\",\n",
      "\u001b[36m(WorkerDict pid=5618)\u001b[0m     \"full_attention\",\n",
      "\u001b[36m(WorkerDict pid=5618)\u001b[0m     \"full_attention\",\n",
      "\u001b[36m(WorkerDict pid=5618)\u001b[0m     \"full_attention\"\n",
      "\u001b[36m(WorkerDict pid=5618)\u001b[0m   ],\n",
      "\u001b[36m(WorkerDict pid=5618)\u001b[0m   \"max_position_embeddings\": 262144,\n",
      "\u001b[36m(WorkerDict pid=5618)\u001b[0m   \"max_window_layers\": 36,\n",
      "\u001b[36m(WorkerDict pid=5618)\u001b[0m   \"model_type\": \"qwen3\",\n",
      "\u001b[36m(WorkerDict pid=5618)\u001b[0m   \"num_attention_heads\": 32,\n",
      "\u001b[36m(WorkerDict pid=5618)\u001b[0m   \"num_hidden_layers\": 36,\n",
      "\u001b[36m(WorkerDict pid=5618)\u001b[0m   \"num_key_value_heads\": 8,\n",
      "\u001b[36m(WorkerDict pid=5618)\u001b[0m   \"pad_token_id\": 151643,\n",
      "\u001b[36m(WorkerDict pid=5618)\u001b[0m   \"rms_norm_eps\": 1e-06,\n",
      "\u001b[36m(WorkerDict pid=5618)\u001b[0m   \"rope_scaling\": null,\n",
      "\u001b[36m(WorkerDict pid=5618)\u001b[0m   \"rope_theta\": 5000000,\n",
      "\u001b[36m(WorkerDict pid=5618)\u001b[0m   \"sliding_window\": null,\n",
      "\u001b[36m(WorkerDict pid=5618)\u001b[0m   \"tie_word_embeddings\": true,\n",
      "\u001b[36m(WorkerDict pid=5618)\u001b[0m   \"torch_dtype\": \"bfloat16\",\n",
      "\u001b[36m(WorkerDict pid=5618)\u001b[0m   \"transformers_version\": \"4.53.2\",\n",
      "\u001b[36m(WorkerDict pid=5618)\u001b[0m   \"use_cache\": true,\n",
      "\u001b[36m(WorkerDict pid=5618)\u001b[0m   \"use_sliding_window\": false,\n",
      "\u001b[36m(WorkerDict pid=5618)\u001b[0m   \"vocab_size\": 151936\n",
      "\u001b[36m(WorkerDict pid=5618)\u001b[0m }\n",
      "\u001b[36m(WorkerDict pid=5618)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(WorkerDict pid=5618)\u001b[0m Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen3ForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained(\"openai/whisper-tiny\", attn_implementation=\"flash_attention_2\", torch_dtype=torch.float16)`\n",
      "\u001b[36m(WorkerDict pid=5618)\u001b[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.\n",
      "\u001b[36m(WorkerDict pid=5618)\u001b[0m \rLoading checkpoint shards:   0%|                                                         | 0/3 [00:00<?, ?it/s]\n",
      "\u001b[36m(WorkerDict pid=5618)\u001b[0m \rLoading checkpoint shards:  33%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                | 1/3 [00:02<00:05,  2.65s/it]\n",
      "\u001b[36m(WorkerDict pid=5618)\u001b[0m \rLoading checkpoint shards:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                | 2/3 [00:06<00:03,  3.10s/it]\n",
      "\u001b[36m(WorkerDict pid=5618)\u001b[0m \rLoading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:06<00:00,  2.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(WorkerDict pid=5618)\u001b[0m Monkey patch state_dict in AutoModelForCausalLMWithValueHead. \n",
      "\u001b[36m(WorkerDict pid=5618)\u001b[0m Monkey patch _flash_attention_forward in transformers.integrations.flash_attention\n",
      "\u001b[36m(WorkerDict pid=5618)\u001b[0m Skipping monkey patch for Qwen3ForCausalLM as use_fused_kernels is False or fused_kernels_backend is torch\n",
      "\u001b[36m(WorkerDict pid=5618)\u001b[0m Qwen3ForCausalLM contains 4.02B parameters\n",
      "\u001b[36m(WorkerDict pid=5618)\u001b[0m wrap_policy: functools.partial(<function _or_policy at 0x2b360f6e36d0>, policies=[functools.partial(<function transformer_auto_wrap_policy at 0x2b360f6e35b0>, transformer_layer_cls={<class 'transformers.models.qwen3.modeling_qwen3.Qwen3DecoderLayer'>})])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(WorkerDict pid=5618)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/distributed/fsdp/_init_utils.py:430: UserWarning: FSDP is switching to use `NO_SHARD` instead of ShardingStrategy.FULL_SHARD since the world size is 1.\n",
      "\u001b[36m(WorkerDict pid=5618)\u001b[0m   warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(WorkerDict pid=5618)\u001b[0m Total steps: 122335, num_warmup_steps: 0\n",
      "\u001b[36m(WorkerDict pid=5618)\u001b[0m Actor use_remove_padding=True\n",
      "\u001b[36m(WorkerDict pid=5618)\u001b[0m Actor use_fused_kernels=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(WorkerDict pid=5618)\u001b[0m /workspace/rllm/verl/verl/utils/profiler/config.py:49: UserWarning: Torch profiler tool config is not fully supported now.\n",
      "\u001b[36m(WorkerDict pid=5618)\u001b[0m   warnings.warn(\"Torch profiler tool config is not fully supported now.\", stacklevel=1)\n",
      "\u001b[36m(WorkerDict pid=5618)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:680: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .\n",
      "\u001b[36m(WorkerDict pid=5618)\u001b[0m   warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m [VLLM_SERVER_PATCH] vLLMReplica instance created with InstrumentedvLLMHttpServer\n",
      "\u001b[36m(pid=5924)\u001b[0m WARNING 11-19 03:54:10 [api_server.py:1177] LoRA dynamic loading & unloading is enabled in the API server. This should ONLY be used for local development!\n",
      "\u001b[36m(InstrumentedvLLMHttpServer pid=5924)\u001b[0m [VLLM_SERVER_PATCH] InstrumentedvLLMHttpServer.__init__ called in Ray worker pid=5924\n",
      "\u001b[36m(InstrumentedvLLMHttpServer pid=5924)\u001b[0m [VLLM_SERVER_PATCH] Calling instrument_vllm() in Ray worker pid=5924\n",
      "\u001b[36m(InstrumentedvLLMHttpServer pid=5924)\u001b[0m [VLLM_SERVER_PATCH] instrument_vllm() returned: True\n",
      "\u001b[36m(InstrumentedvLLMHttpServer pid=5924)\u001b[0m ['serve',\n",
      "\u001b[36m(InstrumentedvLLMHttpServer pid=5924)\u001b[0m  'Qwen/Qwen3-4B-Instruct-2507',\n",
      "\u001b[36m(InstrumentedvLLMHttpServer pid=5924)\u001b[0m  '--dtype',\n",
      "\u001b[36m(InstrumentedvLLMHttpServer pid=5924)\u001b[0m  'bfloat16',\n",
      "\u001b[36m(InstrumentedvLLMHttpServer pid=5924)\u001b[0m  '--load_format',\n",
      "\u001b[36m(InstrumentedvLLMHttpServer pid=5924)\u001b[0m  'dummy',\n",
      "\u001b[36m(InstrumentedvLLMHttpServer pid=5924)\u001b[0m  '--trust_remote_code',\n",
      "\u001b[36m(InstrumentedvLLMHttpServer pid=5924)\u001b[0m  '--max_model_len',\n",
      "\u001b[36m(InstrumentedvLLMHttpServer pid=5924)\u001b[0m  '3072',\n",
      "\u001b[36m(InstrumentedvLLMHttpServer pid=5924)\u001b[0m  '--max_num_seqs',\n",
      "\u001b[36m(InstrumentedvLLMHttpServer pid=5924)\u001b[0m  '1024',\n",
      "\u001b[36m(InstrumentedvLLMHttpServer pid=5924)\u001b[0m  '--enable_chunked_prefill',\n",
      "\u001b[36m(InstrumentedvLLMHttpServer pid=5924)\u001b[0m  '--max_num_batched_tokens',\n",
      "\u001b[36m(InstrumentedvLLMHttpServer pid=5924)\u001b[0m  '8192',\n",
      "\u001b[36m(InstrumentedvLLMHttpServer pid=5924)\u001b[0m  '--enable_prefix_caching',\n",
      "\u001b[36m(InstrumentedvLLMHttpServer pid=5924)\u001b[0m  '--enable_sleep_mode',\n",
      "\u001b[36m(InstrumentedvLLMHttpServer pid=5924)\u001b[0m  '--disable_custom_all_reduce',\n",
      "\u001b[36m(InstrumentedvLLMHttpServer pid=5924)\u001b[0m  '--gpu_memory_utilization',\n",
      "\u001b[36m(InstrumentedvLLMHttpServer pid=5924)\u001b[0m  '0.7',\n",
      "\u001b[36m(InstrumentedvLLMHttpServer pid=5924)\u001b[0m  '--disable_log_stats',\n",
      "\u001b[36m(InstrumentedvLLMHttpServer pid=5924)\u001b[0m  '--tensor_parallel_size',\n",
      "\u001b[36m(InstrumentedvLLMHttpServer pid=5924)\u001b[0m  '1',\n",
      "\u001b[36m(InstrumentedvLLMHttpServer pid=5924)\u001b[0m  '--seed',\n",
      "\u001b[36m(InstrumentedvLLMHttpServer pid=5924)\u001b[0m  '0',\n",
      "\u001b[36m(InstrumentedvLLMHttpServer pid=5924)\u001b[0m  '--override_generation_config',\n",
      "\u001b[36m(InstrumentedvLLMHttpServer pid=5924)\u001b[0m  '{\"temperature\": 1.0, \"top_k\": -1, \"top_p\": 1.0, \"repetition_penalty\": 1.0, '\n",
      "\u001b[36m(InstrumentedvLLMHttpServer pid=5924)\u001b[0m  '\"max_new_tokens\": 1024}']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(InstrumentedvLLMHttpServer pid=5924)\u001b[0m INFO:2025-11-19 03:54:13,489:vLLMHttpServer, replica_rank: 0, master address: 172.20.1.68, master port: 49260, data parallel master port: 54872\n",
      "\u001b[36m(InstrumentedvLLMHttpServer pid=5924)\u001b[0m INFO:2025-11-19 03:54:13,508:override_generation_config: {'temperature': 1.0, 'top_k': -1, 'top_p': 1.0, 'repetition_penalty': 1.0, 'max_new_tokens': 1024}\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m /workspace/rllm/verl/verl/utils/profiler/config.py:49: UserWarning: Torch profiler tool config is not fully supported now.\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m   warnings.warn(\"Torch profiler tool config is not fully supported now.\", stacklevel=1)\n",
      "\u001b[36m(InstrumentedvLLMHttpServer pid=5924)\u001b[0m Using blocking ray.get inside async actor. This blocks the event loop. Please use `await` on object ref with asyncio.gather if you want to yield execution to the event loop instead.\n",
      "\u001b[36m(InstrumentedvLLMHttpServer pid=5924)\u001b[0m INFO:2025-11-19 03:54:14,180:replica_rank=0, node_rank=0, nnodes=1, get worker zmq addresses: ['ipc:///tmp/verl_vllm_zmq_5618_root.ipc']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(InstrumentedvLLMHttpServer pid=5924)\u001b[0m WARNING 11-19 03:54:21 [arg_utils.py:1695] Detected VLLM_USE_V1=1 with Engine in background thread. Usage should be considered experimental. Please report any issues on Github.\n",
      "\u001b[36m(InstrumentedvLLMHttpServer pid=5924)\u001b[0m WARNING 11-19 03:54:32 [api_server.py:1177] LoRA dynamic loading & unloading is enabled in the API server. This should ONLY be used for local development!\n",
      "\u001b[36m(WorkerDict pid=5618)\u001b[0m WARNING 11-19 03:54:35 [topk_topp_sampler.py:59] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(WorkerDict pid=5618)\u001b[0m \rCapturing CUDA graph shapes:   0%|                                                      | 0/67 [00:00<?, ?it/s]\n",
      "\u001b[36m(WorkerDict pid=5618)\u001b[0m \rCapturing CUDA graph shapes:   4%|â–ˆâ–ˆ                                            | 3/67 [00:00<00:02, 22.47it/s]\n",
      "\u001b[36m(WorkerDict pid=5618)\u001b[0m \rCapturing CUDA graph shapes:   9%|â–ˆâ–ˆâ–ˆâ–ˆ                                          | 6/67 [00:00<00:02, 23.53it/s]\n",
      "\u001b[36m(WorkerDict pid=5618)\u001b[0m \rCapturing CUDA graph shapes:  13%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                       | 9/67 [00:00<00:02, 23.75it/s]\n",
      "\u001b[36m(WorkerDict pid=5618)\u001b[0m \rCapturing CUDA graph shapes:  18%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                     | 12/67 [00:00<00:02, 23.95it/s]\n",
      "\u001b[36m(WorkerDict pid=5618)\u001b[0m \rCapturing CUDA graph shapes:  22%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                   | 15/67 [00:00<00:02, 23.82it/s]\n",
      "\u001b[36m(WorkerDict pid=5618)\u001b[0m \rCapturing CUDA graph shapes:  27%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                 | 18/67 [00:00<00:02, 24.03it/s]\n",
      "\u001b[36m(WorkerDict pid=5618)\u001b[0m \rCapturing CUDA graph shapes:  31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                               | 21/67 [00:00<00:01, 24.39it/s]\n",
      "\u001b[36m(WorkerDict pid=5618)\u001b[0m \rCapturing CUDA graph shapes:  36%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                             | 24/67 [00:00<00:01, 24.60it/s]\n",
      "\u001b[36m(WorkerDict pid=5618)\u001b[0m \rCapturing CUDA graph shapes:  40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                          | 27/67 [00:01<00:01, 24.60it/s]\n",
      "\u001b[36m(WorkerDict pid=5618)\u001b[0m \rCapturing CUDA graph shapes:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                        | 30/67 [00:01<00:01, 24.21it/s]\n",
      "\u001b[36m(WorkerDict pid=5618)\u001b[0m \rCapturing CUDA graph shapes:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                      | 33/67 [00:01<00:01, 24.53it/s]\n",
      "\u001b[36m(WorkerDict pid=5618)\u001b[0m \rCapturing CUDA graph shapes:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                    | 36/67 [00:01<00:01, 25.30it/s]\n",
      "\u001b[36m(WorkerDict pid=5618)\u001b[0m \rCapturing CUDA graph shapes:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                  | 39/67 [00:01<00:01, 25.93it/s]\n",
      "\u001b[36m(WorkerDict pid=5618)\u001b[0m \rCapturing CUDA graph shapes:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                | 42/67 [00:01<00:00, 25.57it/s]\n",
      "\u001b[36m(WorkerDict pid=5618)\u001b[0m \rCapturing CUDA graph shapes:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–              | 45/67 [00:01<00:00, 24.56it/s]\n",
      "\u001b[36m(WorkerDict pid=5618)\u001b[0m \rCapturing CUDA graph shapes:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–            | 48/67 [00:01<00:00, 24.98it/s]\n",
      "\u001b[36m(WorkerDict pid=5618)\u001b[0m \rCapturing CUDA graph shapes:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž          | 51/67 [00:02<00:00, 25.02it/s]\n",
      "\u001b[36m(WorkerDict pid=5618)\u001b[0m \rCapturing CUDA graph shapes:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž        | 54/67 [00:02<00:00, 25.51it/s]\n",
      "\u001b[36m(WorkerDict pid=5618)\u001b[0m \rCapturing CUDA graph shapes:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž      | 57/67 [00:02<00:00, 25.84it/s]\n",
      "\u001b[36m(WorkerDict pid=5618)\u001b[0m \rCapturing CUDA graph shapes:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 60/67 [00:02<00:00, 25.80it/s]\n",
      "\u001b[36m(WorkerDict pid=5618)\u001b[0m \rCapturing CUDA graph shapes:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 63/67 [00:02<00:00, 26.17it/s]\n",
      "\u001b[36m(WorkerDict pid=5618)\u001b[0m \rCapturing CUDA graph shapes:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 66/67 [00:02<00:00, 24.32it/s]\n",
      "\u001b[36m(WorkerDict pid=5618)\u001b[0m \rCapturing CUDA graph shapes: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:02<00:00, 24.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(InstrumentedvLLMHttpServer pid=5924)\u001b[0m WARNING 11-19 03:55:48 [config.py:1528] Default sampling parameters have been overridden by the model's Hugging Face generation config recommended from the model creator. If this is not intended, please relaunch vLLM instance with `--generation-config vllm`.\n",
      "\u001b[36m(WorkerDict pid=5618)\u001b[0m WARNING 11-19 03:54:34 [api_server.py:1177] LoRA dynamic loading & unloading is enabled in the API server. This should ONLY be used for local development!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(InstrumentedvLLMHttpServer pid=5924)\u001b[0m INFO:2025-11-19 03:55:48,190:Initializing a V1 LLM engine with config: model='Qwen/Qwen3-4B-Instruct-2507', speculative_config=None, tokenizer='Qwen/Qwen3-4B-Instruct-2507', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config={}, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=3072, download_dir=None, load_format=dummy, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_backend=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-4B-Instruct-2507, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, pooler_config=None, compilation_config={\"level\":3,\"debug_dump_path\":\"\",\"cache_dir\":\"\",\"backend\":\"\",\"custom_ops\":[],\"splitting_ops\":[\"vllm.unified_attention\",\"vllm.unified_attention_with_output\",\"vllm.mamba_mixer2\"],\"use_inductor\":true,\"compile_sizes\":[],\"inductor_compile_config\":{\"enable_auto_functionalized_v2\":false},\"inductor_passes\":{},\"use_cudagraph\":true,\"cudagraph_num_of_warmups\":1,\"cudagraph_capture_sizes\":[512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"cudagraph_copy_inputs\":false,\"full_cuda_graph\":false,\"max_capture_size\":512,\"local_cache_dir\":null}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m train_sampling_params: {'temperature': 1.0, 'top_k': -1, 'top_p': 1.0}\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m val_sampling_params: {'temperature': 1.0, 'top_k': -1, 'top_p': 1.0}\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m [PROXY_MANAGER] vLLM token IDs support: none\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m [PROXY_MANAGER] Detailed instrumentation status: {'vllm_available': True, 'vllm_version': '0.10.0', 'is_instrumented_flag': False, 'has_patched_generator': False, 'has_patched_response_class': False, 'generator_name': 'chat_completion_full_generator'}\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m Initialized VerlProxyManager with 1 vLLM replicas. Proxy endpoint: http://127.0.0.1:4000/v1\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m Checkpoint tracker file does not exist: /tmp/ray/session_2025-11-19_03-52-25_294110_271/runtime_resources/working_dir_files/_ray_pkg_d80ef6786f7cd5fa/checkpoints/solver-judge-workflow/sdk-solver-judge/latest_checkpointed_iteration.txt\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m Training from scratch\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m Time taken to validate agent: 2.4318695068359375e-05\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m 'epoch 0, step 1 started'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m WARNING:2025-11-19 03:55:49,545:vLLM < 0.10.2 detected, but VERL servers are already running. Token IDs will NOT be available! To enable token IDs, call instrument_vllm() BEFORE creating AgentLoopManager. See docs/howto/instrument_verl_vllm_for_token_ids.md for details.\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m \rGenerating trajectories:   0%|                                                          | 0/16 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m <answer>75 + (53 - 51)</answer>\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m \u001b[32m[98fe422b-fac1-48df-a21b-4ddda82df4c4:0:1] Rollout completed with reward: 1.0\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m \rGenerating trajectories:   6%|â–ˆâ–ˆâ–ˆâ–                                              | 1/16 [00:08<02:03,  8.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m <answer>75 + (53 - 51)</answer>\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m \u001b[32m[98fe422b-fac1-48df-a21b-4ddda82df4c4:1:1] Rollout completed with reward: 1.0\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m \rGenerating trajectories:  12%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                           | 2/16 [00:08<00:48,  3.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m <answer>24 - (3 - 2)</answer>\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m \u001b[32m[8d77c556-c39b-4c4a-960c-09f1030f0a21:0:1] Rollout completed with reward: 1.0\u001b[0m\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m <answer>75 + (53 - 51)</answer>\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m \u001b[32m[98fe422b-fac1-48df-a21b-4ddda82df4c4:2:1] Rollout completed with reward: 1.0\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m \rGenerating trajectories:  19%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                        | 3/16 [00:08<00:26,  2.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m <answer>75 + (53 - 51)</answer>\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m \u001b[32m[98fe422b-fac1-48df-a21b-4ddda82df4c4:3:1] Rollout completed with reward: 1.0\u001b[0m\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m <answer>31 - (81 - 71)</answer>\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m \u001b[32m[a13229f4-abaa-470d-bcf8-ea65221bfa93:2:1] Rollout completed with reward: 1.0\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m \rGenerating trajectories:  31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                  | 5/16 [00:09<00:10,  1.04it/s]\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m \rGenerating trajectories:  38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                               | 6/16 [00:09<00:07,  1.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m <answer>24 - 3 + 2</answer>\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m \u001b[32m[8d77c556-c39b-4c4a-960c-09f1030f0a21:3:1] Rollout completed with reward: 1.0\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m \rGenerating trajectories:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                            | 7/16 [00:09<00:05,  1.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m <answer>31 - (81 - 71)</answer>\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m \u001b[32m[a13229f4-abaa-470d-bcf8-ea65221bfa93:1:1] Rollout completed with reward: 1.0\u001b[0m\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m <answer>31 - (81 - 71)</answer>\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m \u001b[32m[a13229f4-abaa-470d-bcf8-ea65221bfa93:3:1] Rollout completed with reward: 1.0\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m \rGenerating trajectories:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                         | 8/16 [00:09<00:03,  2.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m <answer>24 - 3 + 2</answer>\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m \u001b[32m[8d77c556-c39b-4c4a-960c-09f1030f0a21:1:1] Rollout completed with reward: 1.0\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m \rGenerating trajectories:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                  | 10/16 [00:10<00:02,  2.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m <answer>31 - (81 - 71)</answer>\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m \u001b[32m[a13229f4-abaa-470d-bcf8-ea65221bfa93:0:1] Rollout completed with reward: 1.0\u001b[0m\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m <answer>97 - 17 - 11 - 9</answer>\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m \u001b[32m[bd07e2e4-fa11-4cc8-8448-db61762dbc6d:1:1] Rollout completed with reward: 1.0\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m \rGenerating trajectories:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹               | 11/16 [00:10<00:02,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m <answer>24 + 2 - 3</answer>\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m \u001b[32m[8d77c556-c39b-4c4a-960c-09f1030f0a21:2:1] Rollout completed with reward: 1.0\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m \rGenerating trajectories:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š         | 13/16 [00:11<00:01,  2.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m <answer>97 - 17 - 11 - 9</answer>\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m \u001b[32m[bd07e2e4-fa11-4cc8-8448-db61762dbc6d:3:1] Rollout completed with reward: 1.0\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m \rGenerating trajectories:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰      | 14/16 [00:12<00:01,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m <answer>(97 - 17) - (11 + 9)</answer>\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m \u001b[32m[bd07e2e4-fa11-4cc8-8448-db61762dbc6d:2:1] Rollout completed with reward: 1.0\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m \rGenerating trajectories:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 15/16 [00:12<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m <answer>97 - (17 + 11) - 9</answer>\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m \u001b[32m[bd07e2e4-fa11-4cc8-8448-db61762dbc6d:0:1] Rollout completed with reward: 1.0\u001b[0m\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m Total time for generating trajectories: 14.96 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m \rGenerating trajectories: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:14<00:00,  1.10it/s]\rGenerating trajectories: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:14<00:00,  1.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m \u001b[36m\u001b[1m\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m ============================================================\u001b[0m\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m \u001b[36m\u001b[1mEpisode: bd07e2e4-fa11-4cc8-8448-db61762dbc6d:0:1  | Traj: bd07e2e4-fa11-4cc8-8448-db61762dbc6d_agent\u001b[0m\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m \u001b[32m\u001b[1mOutcome: âœ“ Correct\u001b[0m\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m \u001b[33mTermination: unknown\u001b[0m\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m [\u001b[37mwhite=masked\u001b[0m \u001b[34mblue=unmasked\u001b[0m \u001b[42m green bg=reward>0 \u001b[0m \u001b[41m red bg=reward<=0 \u001b[0m]\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m \u001b[37m<|im_start|>\u001b[0m\u001b[37muser\u001b[0m\u001b[37m\\n\u001b[0m\u001b[37mUsing\u001b[0m\u001b[37m the\u001b[0m\u001b[37m numbers\u001b[0m\u001b[37m \u001b[0m\u001b[37m9\u001b[0m\u001b[37m,\u001b[0m\u001b[37m \u001b[0m\u001b[37m1\u001b[0m\u001b[37m1\u001b[0m\u001b[37m,\u001b[0m\u001b[37m \u001b[0m\u001b[37m9\u001b[0m\u001b[37m7\u001b[0m\u001b[37m,\u001b[0m\u001b[37m \u001b[0m\u001b[37m1\u001b[0m\u001b[37m7\u001b[0m\u001b[37m,\u001b[0m\u001b[37m find\u001b[0m\u001b[37m a\u001b[0m\u001b[37m way\u001b[0m\u001b[37m to\u001b[0m\u001b[37m reach\u001b[0m\u001b[37m the\u001b[0m\u001b[37m target\u001b[0m\u001b[37m number\u001b[0m\u001b[37m \u001b[0m\u001b[37m6\u001b[0m\u001b[37m0\u001b[0m\u001b[37m.\u001b[0m\u001b[37m You\u001b[0m\u001b[37m can\u001b[0m\u001b[37m use\u001b[0m\u001b[37m basic\u001b[0m\u001b[37m arithmetic\u001b[0m\u001b[37m operations\u001b[0m\u001b[37m (+\u001b[0m\u001b[37m,\u001b[0m\u001b[37m -,\u001b[0m\u001b[37m *,\u001b[0m\u001b[37m /\u001b[0m\u001b[37m)\u001b[0m\u001b[37m and\u001b[0m\u001b[37m each\u001b[0m\u001b[37m number\u001b[0m\u001b[37m can\u001b[0m\u001b[37m only\u001b[0m\u001b[37m be\u001b[0m\u001b[37m used\u001b[0m\u001b[37m once\u001b[0m\u001b[37m.\u001b[0m\u001b[37m Show\u001b[0m\u001b[37m your\u001b[0m\u001b[37m step\u001b[0m\u001b[37m-by\u001b[0m\u001b[37m-step\u001b[0m\u001b[37m calculation\u001b[0m\u001b[37m and\u001b[0m\u001b[37m output\u001b[0m\u001b[37m the\u001b[0m\u001b[37m final\u001b[0m\u001b[37m answer\u001b[0m\u001b[37m within\u001b[0m\u001b[37m <\u001b[0m\u001b[37manswer\u001b[0m\u001b[37m>\u001b[0m\u001b[37m...</\u001b[0m\u001b[37manswer\u001b[0m\u001b[37m>,\u001b[0m\u001b[37m for\u001b[0m\u001b[37m example\u001b[0m\u001b[37m <\u001b[0m\u001b[37manswer\u001b[0m\u001b[37m>\u001b[0m\u001b[37m (\u001b[0m\u001b[37m1\u001b[0m\u001b[37m +\u001b[0m\u001b[37m \u001b[0m\u001b[37m2\u001b[0m\u001b[37m)\u001b[0m\u001b[37m /\u001b[0m\u001b[37m \u001b[0m\u001b[37m3\u001b[0m\u001b[37m </\u001b[0m\u001b[37manswer\u001b[0m\u001b[37m>\u001b[0m\u001b[37m..\u001b[0m\u001b[37m Output\u001b[0m\u001b[37m the\u001b[0m\u001b[37m final\u001b[0m\u001b[37m answer\u001b[0m\u001b[37m within\u001b[0m\u001b[37m <\u001b[0m\u001b[37manswer\u001b[0m\u001b[37m>\u001b[0m\u001b[37m...</\u001b[0m\u001b[37manswer\u001b[0m\u001b[37m>\u001b[0m\u001b[37m<|im_end|>\u001b[0m\u001b[37m\\n\u001b[0m\u001b[37m<|im_start|>\u001b[0m\u001b[37massistant\u001b[0m\u001b[37m\\n\u001b[0m\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m ----------------\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m \u001b[34mWe\u001b[0m\u001b[34m are\u001b[0m\u001b[34m given\u001b[0m\u001b[34m the\u001b[0m\u001b[34m numbers\u001b[0m\u001b[34m:\u001b[0m\u001b[34m \u001b[0m\u001b[34m9\u001b[0m\u001b[34m,\u001b[0m\u001b[34m \u001b[0m\u001b[34m1\u001b[0m\u001b[34m1\u001b[0m\u001b[34m,\u001b[0m\u001b[34m \u001b[0m\u001b[34m9\u001b[0m\u001b[34m7\u001b[0m\u001b[34m,\u001b[0m\u001b[34m \u001b[0m\u001b[34m1\u001b[0m\u001b[34m7\u001b[0m\u001b[34m  \\n\u001b[0m\u001b[34mTarget\u001b[0m\u001b[34m:\u001b[0m\u001b[34m \u001b[0m\u001b[34m6\u001b[0m\u001b[34m0\u001b[0m\u001b[34m  \\n\u001b[0m\u001b[34mWe\u001b[0m\u001b[34m can\u001b[0m\u001b[34m use\u001b[0m\u001b[34m basic\u001b[0m\u001b[34m arithmetic\u001b[0m\u001b[34m operations\u001b[0m\u001b[34m:\u001b[0m\u001b[34m +\u001b[0m\u001b[34m,\u001b[0m\u001b[34m âˆ’\u001b[0m\u001b[34m,\u001b[0m\u001b[34m Ã—\u001b[0m\u001b[34m,\u001b[0m\u001b[34m ï¿½\u001b[0m\u001b[34mï¿½\u001b[0m\u001b[34m  \\n\u001b[0m\u001b[34mEach\u001b[0m\u001b[34m number\u001b[0m\u001b[34m can\u001b[0m\u001b[34m be\u001b[0m\u001b[34m used\u001b[0m\u001b[34m **\u001b[0m\u001b[34monly\u001b[0m\u001b[34m once\u001b[0m\u001b[34m**\u001b[0m\u001b[34m.\\n\\n\u001b[0m\u001b[34m---\\n\\n\u001b[0m\u001b[34mLet\u001b[0m\u001b[34mâ€™s\u001b[0m\u001b[34m look\u001b[0m\u001b[34m for\u001b[0m\u001b[34m combinations\u001b[0m\u001b[34m that\u001b[0m\u001b[34m get\u001b[0m\u001b[34m us\u001b[0m\u001b[34m close\u001b[0m\u001b[34m to\u001b[0m\u001b[34m \u001b[0m\u001b[34m6\u001b[0m\u001b[34m0\u001b[0m\u001b[34m.\\n\\n\u001b[0m\u001b[34mFirst\u001b[0m\u001b[34m,\u001b[0m\u001b[34m note\u001b[0m\u001b[34m that\u001b[0m\u001b[34m \u001b[0m\u001b[34m9\u001b[0m\u001b[34m7\u001b[0m\u001b[34m is\u001b[0m\u001b[34m quite\u001b[0m\u001b[34m large\u001b[0m\u001b[34m.\u001b[0m\u001b[34m If\u001b[0m\u001b[34m we\u001b[0m\u001b[34m subtract\u001b[0m\u001b[34m something\u001b[0m\u001b[34m from\u001b[0m\u001b[34m \u001b[0m\u001b[34m9\u001b[0m\u001b[34m7\u001b[0m\u001b[34m,\u001b[0m\u001b[34m we\u001b[0m\u001b[34m might\u001b[0m\u001b[34m get\u001b[0m\u001b[34m close\u001b[0m\u001b[34m to\u001b[0m\u001b[34m \u001b[0m\u001b[34m6\u001b[0m\u001b[34m0\u001b[0m\u001b[34m.\\n\\n\u001b[0m\u001b[34mTry\u001b[0m\u001b[34m:\u001b[0m\u001b[34m \u001b[0m\u001b[34m9\u001b[0m\u001b[34m7\u001b[0m\u001b[34m âˆ’\u001b[0m\u001b[34m \u001b[0m\u001b[34m1\u001b[0m\u001b[34m1\u001b[0m\u001b[34m =\u001b[0m\u001b[34m \u001b[0m\u001b[34m8\u001b[0m\u001b[34m6\u001b[0m\u001b[34m â†’\u001b[0m\u001b[34m too\u001b[0m\u001b[34m high\u001b[0m\u001b[34m  \\n\u001b[0m\u001b[34m9\u001b[0m\u001b[34m7\u001b[0m\u001b[34m âˆ’\u001b[0m\u001b[34m \u001b[0m\u001b[34m1\u001b[0m\u001b[34m7\u001b[0m\u001b[34m =\u001b[0m\u001b[34m \u001b[0m\u001b[34m8\u001b[0m\u001b[34m0\u001b[0m\u001b[34m â†’\u001b[0m\u001b[34m too\u001b[0m\u001b[34m high\u001b[0m\u001b[34m  \\n\u001b[0m\u001b[34m9\u001b[0m\u001b[34m7\u001b[0m\u001b[34m âˆ’\u001b[0m\u001b[34m \u001b[0m\u001b[34m9\u001b[0m\u001b[34m =\u001b[0m\u001b[34m \u001b[0m\u001b[34m8\u001b[0m\u001b[34m8\u001b[0m\u001b[34m â†’\u001b[0m\u001b[34m too\u001b[0m\u001b[34m high\u001b[0m\u001b[34m\\n\\n\u001b[0m\u001b[34mWhat\u001b[0m\u001b[34m if\u001b[0m\u001b[34m we\u001b[0m\u001b[34m do\u001b[0m\u001b[34m:\u001b[0m\u001b[34m \u001b[0m\u001b[34m9\u001b[0m\u001b[34m7\u001b[0m\u001b[34m âˆ’\u001b[0m\u001b[34m (\u001b[0m\u001b[34m1\u001b[0m\u001b[34m7\u001b[0m\u001b[34m +\u001b[0m\u001b[34m \u001b[0m\u001b[34m1\u001b[0m\u001b[34m1\u001b[0m\u001b[34m)\u001b[0m\u001b[34m =\u001b[0m\u001b[34m \u001b[0m\u001b[34m9\u001b[0m\u001b[34m7\u001b[0m\u001b[34m âˆ’\u001b[0m\u001b[34m \u001b[0m\u001b[34m2\u001b[0m\u001b[34m8\u001b[0m\u001b[34m =\u001b[0m\u001b[34m \u001b[0m\u001b[34m6\u001b[0m\u001b[34m9\u001b[0m\u001b[34m â†’\u001b[0m\u001b[34m close\u001b[0m\u001b[34m to\u001b[0m\u001b[34m \u001b[0m\u001b[34m6\u001b[0m\u001b[34m0\u001b[0m\u001b[34m  \\n\u001b[0m\u001b[34m6\u001b[0m\u001b[34m9\u001b[0m\u001b[34m âˆ’\u001b[0m\u001b[34m \u001b[0m\u001b[34m9\u001b[0m\u001b[34m =\u001b[0m\u001b[34m \u001b[0m\u001b[34m6\u001b[0m\u001b[34m0\u001b[0m\u001b[34m â†’\u001b[0m\u001b[34m yes\u001b[0m\u001b[34m!\\n\\n\u001b[0m\u001b[34mLet\u001b[0m\u001b[34mâ€™s\u001b[0m\u001b[34m check\u001b[0m\u001b[34m:\\n\\n\u001b[0m\u001b[34m(\u001b[0m\u001b[34m1\u001b[0m\u001b[34m7\u001b[0m\u001b[34m +\u001b[0m\u001b[34m \u001b[0m\u001b[34m1\u001b[0m\u001b[34m1\u001b[0m\u001b[34m)\u001b[0m\u001b[34m =\u001b[0m\u001b[34m \u001b[0m\u001b[34m2\u001b[0m\u001b[34m8\u001b[0m\u001b[34m  \\n\u001b[0m\u001b[34m9\u001b[0m\u001b[34m7\u001b[0m\u001b[34m âˆ’\u001b[0m\u001b[34m \u001b[0m\u001b[34m2\u001b[0m\u001b[34m8\u001b[0m\u001b[34m =\u001b[0m\u001b[34m \u001b[0m\u001b[34m6\u001b[0m\u001b[34m9\u001b[0m\u001b[34m  \\n\u001b[0m\u001b[34m6\u001b[0m\u001b[34m9\u001b[0m\u001b[34m âˆ’\u001b[0m\u001b[34m \u001b[0m\u001b[34m9\u001b[0m\u001b[34m =\u001b[0m\u001b[34m \u001b[0m\u001b[34m6\u001b[0m\u001b[34m0\u001b[0m\u001b[34m\\n\\n\u001b[0m\u001b[34mPerfect\u001b[0m\u001b[34m!\\n\\n\u001b[0m\u001b[34mSo\u001b[0m\u001b[34m the\u001b[0m\u001b[34m expression\u001b[0m\u001b[34m is\u001b[0m\u001b[34m:\\n\\n\u001b[0m\u001b[34m9\u001b[0m\u001b[34m7\u001b[0m\u001b[34m âˆ’\u001b[0m\u001b[34m (\u001b[0m\u001b[34m1\u001b[0m\u001b[34m7\u001b[0m\u001b[34m +\u001b[0m\u001b[34m \u001b[0m\u001b[34m1\u001b[0m\u001b[34m1\u001b[0m\u001b[34m)\u001b[0m\u001b[34m âˆ’\u001b[0m\u001b[34m \u001b[0m\u001b[34m9\u001b[0m\u001b[34m =\u001b[0m\u001b[34m \u001b[0m\u001b[34m6\u001b[0m\u001b[34m0\u001b[0m\u001b[34m\\n\\n\u001b[0m\u001b[34mWe\u001b[0m\u001b[34m used\u001b[0m\u001b[34m all\u001b[0m\u001b[34m numbers\u001b[0m\u001b[34m exactly\u001b[0m\u001b[34m once\u001b[0m\u001b[34m.\\n\\n\u001b[0m\u001b[34mLet\u001b[0m\u001b[34mâ€™s\u001b[0m\u001b[34m verify\u001b[0m\u001b[34m:\\n\\n\u001b[0m\u001b[34m1\u001b[0m\u001b[34m7\u001b[0m\u001b[34m +\u001b[0m\u001b[34m \u001b[0m\u001b[34m1\u001b[0m\u001b[34m1\u001b[0m\u001b[34m =\u001b[0m\u001b[34m \u001b[0m\u001b[34m2\u001b[0m\u001b[34m8\u001b[0m\u001b[34m  \\n\u001b[0m\u001b[34m9\u001b[0m\u001b[34m7\u001b[0m\u001b[34m âˆ’\u001b[0m\u001b[34m \u001b[0m\u001b[34m2\u001b[0m\u001b[34m8\u001b[0m\u001b[34m =\u001b[0m\u001b[34m \u001b[0m\u001b[34m6\u001b[0m\u001b[34m9\u001b[0m\u001b[34m  \\n\u001b[0m\u001b[34m6\u001b[0m\u001b[34m9\u001b[0m\u001b[34m âˆ’\u001b[0m\u001b[34m \u001b[0m\u001b[34m9\u001b[0m\u001b[34m =\u001b[0m\u001b[34m \u001b[0m\u001b[34m6\u001b[0m\u001b[34m0\u001b[0m\u001b[34m ï¿½\u001b[0m\u001b[34mï¿½\u001b[0m\u001b[34m\\n\\n\u001b[0m\u001b[34m<\u001b[0m\u001b[34manswer\u001b[0m\u001b[34m>\u001b[0m\u001b[34m9\u001b[0m\u001b[34m7\u001b[0m\u001b[34m -\u001b[0m\u001b[34m (\u001b[0m\u001b[34m1\u001b[0m\u001b[34m7\u001b[0m\u001b[34m +\u001b[0m\u001b[34m \u001b[0m\u001b[34m1\u001b[0m\u001b[34m1\u001b[0m\u001b[34m)\u001b[0m\u001b[34m -\u001b[0m\u001b[34m \u001b[0m\u001b[34m9\u001b[0m\u001b[34m</\u001b[0m\u001b[34manswer\u001b[0m\u001b[34m>\u001b[0m\u001b[41m\u001b[34m<|im_end|>\u001b[0m\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m step:1 - actor/entropy:0.16445618867874146 - global_seqlen/min:21963 - global_seqlen/max:21963 - global_seqlen/minmax_diff:0 - global_seqlen/balanced_min:21963 - global_seqlen/balanced_max:21963 - global_seqlen/mean:21963.0 - actor/pg_loss:0.0 - actor/pg_clipfrac:0.0 - actor/ppo_kl:-7.28791249760737e-05 - actor/pg_clipfrac_lower:0.0 - actor/grad_norm:0.0 - perf/mfu/actor:0.1834615054805371 - perf/max_memory_allocated_gb:124.88929176330566 - perf/max_memory_reserved_gb:127.46484375 - perf/cpu_memory_used_gb:46.65031814575195 - actor/lr:1e-06 - training/global_step:1 - training/epoch:0 - critic/score/mean:0.0 - critic/score/max:0.0 - critic/score/min:0.0 - critic/rewards/mean:0.0 - critic/rewards/max:0.0 - critic/rewards/min:0.0 - critic/advantages/mean:0.0 - critic/advantages/max:0.0 - critic/advantages/min:0.0 - critic/returns/mean:0.0 - critic/returns/max:0.0 - critic/returns/min:0.0 - response_length/mean:292.4375 - response_length/max:572.0 - response_length/min:203.0 - response_length/clip_ratio:0.0 - response_length_non_aborted/mean:292.4375 - response_length_non_aborted/max:572.0 - response_length_non_aborted/min:203.0 - response_length_non_aborted/clip_ratio:0.0 - response/aborted_ratio:0.0 - prompt_length/mean:165.125 - prompt_length/max:298.0 - prompt_length/min:101.0 - prompt_length/clip_ratio:0.0 - timing_s/start_profile:0.00012356100000943115 - timing_s/generate_trajectories:19.211010406000014 - timing_s/old_log_prob:4.211988564000023 - timing_s/adv:0.0045660210000164625 - timing_s/update_actor:31.35355242999998 - timing_s/step:54.963911371999984 - timing_s/stop_profile:2.87299997125956e-06 - timing_per_token_ms/adv:0.0002078960524526004 - timing_per_token_ms/update_actor:1.4275623744479342 - perf/total_num_tokens:21963 - perf/time_per_step:54.963911371999984 - perf/throughput:399.5894661017249 - batch/solve_none:0.0 - batch/solve_all:1.0 - batch/solve_partial:0.0 - batch/retry_attempt:1.0 - batch/empty:0.0 - batch/flush_success:1.0 - batch/num_trajectories:1.0 - batch/traces_collected:48.0 - batch/collect_sqlite_time:0.02749490737915039 - batch/flush_time:0.00997161865234375 - batch/max_prompt_length_exceeded:0.0 - batch/max_response_length_exceeded:0.0 - batch/env_done:0.0 - batch/max_turns_exceeded:0.0 - batch/timeout:0.0 - batch/unknown:1.0 - batch/error:0.0 - batch/num_tasks:4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m /workspace/rllm/rllm/trainer/verl/agent_sdk_trainer.py:453: FutureWarning: Warning: Function 'verl.trainer.ppo.metric_utils.reduce_metrics' is deprecated. Please use 'verl.utils.metric.reduce_metrics' instead.\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m   actor_output_metrics = reduce_metrics(actor_output.meta_info[\"metrics\"])\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m \rGenerating trajectories:   0%|                                                          | 0/16 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m <answer>71 - 29 - 17</answer>\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m \u001b[32m[285586cb-033f-4527-9a35-f60b694f632f:3:1] Rollout completed with reward: 1.0\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m \rGenerating trajectories:   6%|â–ˆâ–ˆâ–ˆâ–                                              | 1/16 [00:08<02:01,  8.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m <answer>71 - 29 - 17</answer>\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m \u001b[32m[285586cb-033f-4527-9a35-f60b694f632f:2:1] Rollout completed with reward: 1.0\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m \rGenerating trajectories:  12%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                           | 2/16 [00:08<00:50,  3.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m <answer>70 + (31 - 19)</answer>\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m \u001b[32m[31e0007a-2832-4cf2-acf8-c339e969898b:3:1] Rollout completed with reward: 1.0\u001b[0m\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m <answer>(71 - 29) - 17</answer>\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m \u001b[32m[285586cb-033f-4527-9a35-f60b694f632f:0:1] Rollout completed with reward: 1.0\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m \rGenerating trajectories:  19%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                        | 3/16 [00:09<00:28,  2.17s/it]\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m \rGenerating trajectories:  25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                     | 4/16 [00:09<00:16,  1.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m <answer>71 - 29 - 17</answer>\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m \u001b[32m[285586cb-033f-4527-9a35-f60b694f632f:1:1] Rollout completed with reward: 1.0\u001b[0m\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m <answer>70 + 31 - 19</answer>\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m \u001b[32m[31e0007a-2832-4cf2-acf8-c339e969898b:1:1] Rollout completed with reward: 1.0\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m \rGenerating trajectories:  38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                               | 6/16 [00:09<00:06,  1.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m <answer>70 + (31 - 19)</answer>\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m \u001b[32m[31e0007a-2832-4cf2-acf8-c339e969898b:2:1] Rollout completed with reward: 1.0\u001b[0m\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m <answer>70 + (31 - 19)</answer>\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m \u001b[32m[31e0007a-2832-4cf2-acf8-c339e969898b:0:1] Rollout completed with reward: 1.0\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m \rGenerating trajectories:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                         | 8/16 [00:09<00:03,  2.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m <answer>92 - 43 - 12 - 9</answer>\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m \u001b[32m[e23b4d33-99ce-4edb-86ca-e08daa6c4edf:1:1] Rollout completed with reward: 1.0\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m \rGenerating trajectories:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                     | 9/16 [00:12<00:07,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m <answer>(92 - 43) - (12 + 9)</answer>\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m \u001b[32m[e23b4d33-99ce-4edb-86ca-e08daa6c4edf:3:1] Rollout completed with reward: 1.0\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m \rGenerating trajectories:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                  | 10/16 [00:12<00:05,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m <answer>92 - 43 - 12 - 9</answer>\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m \u001b[32m[e23b4d33-99ce-4edb-86ca-e08daa6c4edf:0:1] Rollout completed with reward: 1.0\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m \rGenerating trajectories:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹               | 11/16 [00:13<00:03,  1.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m <answer>92 - 43 - 12 - 9</answer>\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m \u001b[32m[e23b4d33-99ce-4edb-86ca-e08daa6c4edf:2:1] Rollout completed with reward: 1.0\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m \rGenerating trajectories:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š            | 12/16 [00:14<00:02,  1.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m \n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m \u001b[33m[49b5d3d2-07da-448a-87db-102cd147ccf9:3:1] Rollout completed with reward: 0.0\u001b[0m\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m \n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m \u001b[33m[49b5d3d2-07da-448a-87db-102cd147ccf9:0:1] Rollout completed with reward: 0.0\u001b[0m\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m \n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m \u001b[33m[49b5d3d2-07da-448a-87db-102cd147ccf9:2:1] Rollout completed with reward: 0.0\u001b[0m\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m \n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m \u001b[33m[49b5d3d2-07da-448a-87db-102cd147ccf9:1:1] Rollout completed with reward: 0.0\u001b[0m\n",
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m Total time for generating trajectories: 30.49 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TaskRunner pid=4769)\u001b[0m \rGenerating trajectories:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š         | 13/16 [00:30<00:15,  5.14s/it]\rGenerating trajectories: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:30<00:00,  1.91s/it]\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd4641cc4064e0191573fe9c69df29b",
   "metadata": {},
   "source": [
    "## Bonus: Using @trajectory Decorator for Step-Level Control\n",
    "\n",
    "The `@trajectory` decorator is **equivalent to `with session()`** - both track LLM calls using contextvar.\n",
    "\n",
    "**Key difference:** Both provide `.steps` access for fine-grained control:\n",
    "- `with session() as sess:` â†’ `sess.steps` \n",
    "- `@trajectory(name=\"...\")` â†’ returns `TrajectoryView` with `.steps`\n",
    "\n",
    "**When to use:**\n",
    "- `with session()`: Simple episode tracking\n",
    "- `@trajectory`: Multi-step agents where you want explicit step-level rewards (e.g., reward solver differently from judge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8309879909854d7188b41380fd92a7c3",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from rllm.sdk import trajectory\n",
    "from rllm.sdk.protocol import TrajectoryView\n",
    "\n",
    "\n",
    "class TrainableAgentV2:\n",
    "    \"\"\"A simple math solving agent - TRAINABLE VERSION V2\"\"\"\n",
    "\n",
    "    def __init__(self, api_key: str, model: str = \"gpt-4o-mini\"):\n",
    "        # Replace standard OpenAI client with SDK client\n",
    "        # self.client = AsyncOpenAI(api_key=api_key)\n",
    "        self.client = get_chat_client_async(api_key=api_key, base_url=proxy_url)\n",
    "        self.model = model\n",
    "\n",
    "    @trajectory(name=\"solver\")\n",
    "    async def solve(self, problem: str) -> str:\n",
    "        \"\"\"Solve a math problem.\"\"\"\n",
    "        response = await self.client.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=[{\"role\": \"user\", \"content\": f\"{problem}. Output the final answer within <answer>...</answer>\"}],\n",
    "            max_tokens=1000,\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "\n",
    "    @trajectory(name=\"judge\")\n",
    "    async def judge(self, problem, solutions: list[str]) -> str:\n",
    "        \"\"\"Judge multiple solutions to a problem.\"\"\"\n",
    "        formatted_solutions = \"\\n\".join([f\"Solution {i + 1}:\\n{sol}\\n\" for i, sol in enumerate(solutions)])\n",
    "        prompt = judge_prompt.format(problem=problem, solutions=formatted_solutions)\n",
    "\n",
    "        response = await self.client.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            max_tokens=1000,\n",
    "        )\n",
    "        return self.parse_solver_answer(response.choices[0].message.content)\n",
    "\n",
    "    def parse_solver_answer(self, solution):\n",
    "        # Find all <answer> tags and return the last one\n",
    "        answer_matches = re.findall(r\"<answer>(.*?)</answer>\", solution, re.IGNORECASE | re.DOTALL)\n",
    "        if answer_matches:\n",
    "            return \"<answer>\" + answer_matches[-1].strip() + \"</answer>\"\n",
    "        return \"No solution found\"\n",
    "\n",
    "    def parse_selected_solution(self, judgment, solutions):\n",
    "        # Find all <answer> tags and use the last one\n",
    "        answer_matches = re.findall(r\"<answer>(.*?)</answer>\", judgment, re.IGNORECASE | re.DOTALL)\n",
    "        if answer_matches:\n",
    "            answer_text = answer_matches[-1].strip()\n",
    "            try:\n",
    "                solution_index = int(answer_text)\n",
    "                return solutions[solution_index - 1]\n",
    "            except (ValueError, IndexError):\n",
    "                return \"\"\n",
    "        return \"\"\n",
    "\n",
    "    async def run(self, problem: str, n_solutions: int = 2, ground_truth: str = None) -> str:\n",
    "        \"\"\"Generate multiple solutions and judge them.\"\"\"\n",
    "        solutions = []\n",
    "        for _ in range(n_solutions):\n",
    "            sol = await self.solve(problem)\n",
    "            solutions.append(sol)\n",
    "\n",
    "        judgment = await self.judge(problem, solutions)\n",
    "        selected_solution = self.parse_selected_solution(judgment.result, solutions)\n",
    "\n",
    "        # assign reward for each step in trajectory\n",
    "        for sol in solutions:\n",
    "            sol.reward = reward_fn(sol.result, ground_truth)\n",
    "            sol.steps[0].reward = sol.reward\n",
    "\n",
    "        judgment.reward = reward_fn(selected_solution, ground_truth)\n",
    "        judgment.steps[0].reward = judgment.reward\n",
    "\n",
    "        return solutions + [judgment]\n",
    "\n",
    "\n",
    "# Use it\n",
    "async def rollout_v2(question: str, ground_truth: str, **kwargs) -> list[TrajectoryView]:\n",
    "    agent = TrainableAgentV2(None, model=\"Qwen/Qwen3-4B-Instruct-2507\")\n",
    "    trajs = await agent.run(question, ground_truth=ground_truth)\n",
    "    return trajs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed186c9a28b402fb0bc4494df01f08d",
   "metadata": {},
   "source": [
    "## How Does Training Work?\n",
    "\n",
    "Here's what happens under the hood:\n",
    "\n",
    "1. **Trace Collection:** The proxy captures all LLM calls (inputs, outputs, tokens, latency)\n",
    "2. **Reward Assignment:** You define what's good (correct answer = 1.0, wrong = 0.0)\n",
    "3. **Training Loop:** The trainer feeds traces + rewards to the model\n",
    "4. **Learning:** The model adjusts weights to maximize rewards\n",
    "5. **Improvement:** Over time, the model learns successful behaviors\n",
    "\n",
    "This is reinforcement learning: try different approaches, get feedback, learn what works."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1e1581032b452c9409d6c6813c49d1",
   "metadata": {},
   "source": [
    "## Design Details (For The Curious)\n",
    "\n",
    "**Why a proxy?**  \n",
    "Transparent LLM call interception without modifying agent code. Works with any OpenAI-compatible API.\n",
    "\n",
    "**How does session tracking work?**  \n",
    "Uses Python's **contextvar** for automatic context propagation. `with session()` or `@trajectory` creates a context that automatically groups all LLM calls inside it. Thread-safe, zero manual tracking.\n",
    "\n",
    "**Session vs Trajectory:**  \n",
    "Both use contextvar under the hood:\n",
    "- `with session()`: Returns session object with `._uid` for retrieval\n",
    "- `@trajectory`: Returns `TrajectoryView` with `.steps` for fine-grained control\n",
    "\n",
    "**Why SQLite storage?**  \n",
    "Offline training with no live service dependencies. Query and analyze traces anytime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379cbbc1e968416e875cc15c1202d7eb",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Cleanup\n",
    "proxy_manager.shutdown_proxy()\n",
    "print(\"âœ“ Proxy shutdown complete\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}